# llm_assistant/llm_client.py
import requests
import json
import time
import numpy as np
import re


class LLMClient:
    def __init__(self, api_key="", model_name="qwen3-14b", server_url="http://10.200.1.35:8888/v1/completions",
                 timeout_connect=120, timeout_read=300, use_mock=True):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        
        Args:
            api_key: APIå¯†é’¥ï¼ˆæ­¤å¤„å¯é€‰ï¼‰
            model_name: æ¨¡å‹åç§°
            server_url: LLMæœåŠ¡å™¨URL
            timeout_connect: è¿æ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰- å¢åŠ åˆ°120ç§’
            timeout_read: è¯»å–è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰- å¢åŠ åˆ°300ç§’
            use_mock: å½“LLMæœåŠ¡ä¸å¯ç”¨æ—¶ï¼Œæ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿå“åº”
        """
        self.api_key = api_key
        self.model_name = model_name
        self.server_url = server_url
        self.timeout_connect = timeout_connect
        self.timeout_read = timeout_read
        self.use_mock = use_mock
        print(f"åˆå§‹åŒ–LLMå®¢æˆ·ç«¯: {self.server_url}, æ¨¡å‹: {self.model_name}")
        print(f"è¶…æ—¶è®¾ç½®: è¿æ¥è¶…æ—¶={self.timeout_connect}s, è¯»å–è¶…æ—¶={self.timeout_read}s")
        print(f"æ¨¡æ‹Ÿæ¨¡å¼: {'å¼€å¯' if self.use_mock else 'å…³é—­'}")

    def query(self, prompt):
        """å‘LLMå‘é€æŸ¥è¯¢å¹¶è·å–å“åº” - å•æ¬¡è¯·æ±‚ï¼Œé•¿æ—¶é—´ç­‰å¾…"""
        try:
            headers = {
                "Content-Type": "application/json",
            }
            # ä»…å½“APIå¯†é’¥ä¸ä¸ºç©ºæ—¶æ·»åŠ Authorizationå¤´
            if self.api_key and self.api_key != "":
                headers["Authorization"] = f"Bearer {self.api_key}"
                
            data = {
                "model": self.model_name,
                "prompt": prompt,
                "max_tokens": 2048,  # è¿”å›å†…å®¹çš„æœ€å¤§é•¿åº¦
                "temperature": 0.1,  # é™ä½éšæœºæ€§ï¼Œä½¿è¾“å‡ºæ›´ç¡®å®š
                "stream": False      # ä¸ä½¿ç”¨æµå¼è¿”å›
            }
            
            print(f"\n=== å‘é€LLMè¯·æ±‚ ===")
            print(f"ç›®æ ‡æœåŠ¡å™¨: {self.server_url}")
            print(f"æ¨¡å‹åç§°: {self.model_name}")
            print(f"æç¤ºé•¿åº¦: {len(prompt)}å­—ç¬¦")
            print(f"è¿æ¥è¶…æ—¶: {self.timeout_connect}ç§’")
            print(f"è¯»å–è¶…æ—¶: {self.timeout_read}ç§’")
            print("å¼€å§‹å‘é€è¯·æ±‚ï¼Œè¯·è€å¿ƒç­‰å¾…LLMå“åº”...")
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # å‘é€è¯·æ±‚å¹¶ç­‰å¾…å“åº”
            response = requests.post(
                self.server_url, 
                headers=headers, 
                json=data, 
                timeout=(self.timeout_connect, self.timeout_read)  # (è¿æ¥è¶…æ—¶, è¯»å–è¶…æ—¶)
            )
            
            # è®¡ç®—å“åº”æ—¶é—´
            response_time = time.time() - start_time
            print(f"è¯·æ±‚å®Œæˆï¼Œè€—æ—¶: {response_time:.2f}ç§’")
            print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code != 200:
                error_text = response.text[:500] if response.text else "æ— é”™è¯¯ä¿¡æ¯"
                print(f"LLMæœåŠ¡è¿”å›é”™è¯¯çŠ¶æ€ç : {response.status_code}")
                print(f"é”™è¯¯å“åº”å†…å®¹: {error_text}")
                raise Exception(f"LLMæœåŠ¡è¿”å›é”™è¯¯: HTTP {response.status_code}")
            
            # è§£æå“åº”JSON
            try:
                response_data = response.json()
            except json.JSONDecodeError as e:
                print(f"å“åº”JSONè§£æå¤±è´¥: {e}")
                print(f"åŸå§‹å“åº”å†…å®¹: {response.text[:1000]}")
                raise Exception("LLMå“åº”æ ¼å¼ä¸æ˜¯æœ‰æ•ˆçš„JSON")
            
            print(f"\n=== LLMå“åº”è§£æ ===")
            print(f"å“åº”æ•°æ®å­—æ®µ: {list(response_data.keys())}")
            
            # æå–å“åº”æ–‡æœ¬
            response_text = None
            
            # é€‚åº”ä¸åŒAPIç»“æ„
            if "choices" in response_data and len(response_data["choices"]) > 0:
                # OpenAIé£æ ¼API
                response_text = response_data["choices"][0].get("text", "").strip()
                print("ä½¿ç”¨OpenAIé£æ ¼APIå“åº”æ ¼å¼")
            elif "response" in response_data:
                # è‡ªå®šä¹‰APIé£æ ¼1
                response_text = response_data["response"].strip()
                print("ä½¿ç”¨è‡ªå®šä¹‰APIå“åº”æ ¼å¼1")
            elif "output" in response_data:
                # è‡ªå®šä¹‰APIé£æ ¼2
                response_text = response_data["output"].strip()
                print("ä½¿ç”¨è‡ªå®šä¹‰APIå“åº”æ ¼å¼2")
            elif "completion" in response_data:
                # è‡ªå®šä¹‰APIé£æ ¼3
                response_text = response_data["completion"].strip()
                print("ä½¿ç”¨è‡ªå®šä¹‰APIå“åº”æ ¼å¼3")
            else:
                # å°è¯•è¿”å›æ•´ä¸ªJSONå­—ç¬¦ä¸²
                response_text = json.dumps(response_data)
                print("ä½¿ç”¨å®Œæ•´JSONä½œä¸ºå“åº”")
            
            if not response_text:
                raise Exception("LLMå“åº”ä¸ºç©ºæˆ–æ— æ³•æå–æœ‰æ•ˆå†…å®¹")
            
            print(f"\n=== LLMåŸå§‹å“åº”å†…å®¹ ===")
            print("=" * 60)
            print(response_text)
            print("=" * 60)
            print(f"å“åº”é•¿åº¦: {len(response_text)}å­—ç¬¦")
            
            return response_text
                
        except requests.exceptions.ConnectTimeout:
            error_msg = f"è¿æ¥è¶…æ—¶: æ— æ³•åœ¨{self.timeout_connect}ç§’å†…è¿æ¥åˆ°LLMæœåŠ¡å™¨ {self.server_url}"
            print(f"\nâŒ {error_msg}")
            raise Exception(error_msg)
        except requests.exceptions.ReadTimeout:
            error_msg = f"è¯»å–è¶…æ—¶: LLMæœåŠ¡å™¨åœ¨{self.timeout_read}ç§’å†…æœªè¿”å›å®Œæ•´å“åº”"
            print(f"\nâŒ {error_msg}")
            raise Exception(error_msg)
        except requests.exceptions.ConnectionError as e:
            error_msg = f"è¿æ¥é”™è¯¯: æ— æ³•å»ºç«‹ä¸LLMæœåŠ¡å™¨çš„è¿æ¥ - {str(e)}"
            print(f"\nâŒ {error_msg}")
            raise Exception(error_msg)
        except Exception as e:
            error_msg = f"LLMæŸ¥è¯¢å¤±è´¥: {str(e)}"
            print(f"\nâŒ {error_msg}")
            raise Exception(error_msg)

    def get_unload_strategy(self, env_state, device_info, edge_info, cloud_info):
        """è·å–å¸è½½ç­–ç•¥å»ºè®®"""
        # æ„å»ºæç¤º
        prompt = self._build_prompt(env_state, device_info, edge_info, cloud_info)
        
        # ä¿å­˜æç¤ºåˆ°æ–‡ä»¶ä»¥ä¾¿è°ƒè¯•
        with open("last_prompt.txt", "w", encoding="utf-8") as f:
            f.write(prompt)
        print(f"å·²ä¿å­˜æç¤ºåˆ° last_prompt.txt (é•¿åº¦: {len(prompt)}å­—ç¬¦)")
        
        print("\nğŸ“¤ å‘é€å¸è½½ç­–ç•¥è¯·æ±‚åˆ°LLM...")
        # æŸ¥è¯¢LLM
        try:
            response = self.query(prompt)
            
            print(f"\nâœ… LLMå“åº”è·å–æˆåŠŸ!")
            
            # ä¿å­˜å“åº”åˆ°æ–‡ä»¶ä»¥ä¾¿è°ƒè¯•
            with open("last_response.txt", "w", encoding="utf-8") as f:
                f.write(response)
            print(f"å·²ä¿å­˜LLMå“åº”åˆ° last_response.txt")
            
            print(f"\nğŸ“‹ å¼€å§‹è§£æLLMå“åº”...")
            # è§£æå“åº”
            strategies = self._extract_json_from_text(response)
            
            if not strategies:
                print("âš ï¸ æ— æ³•è§£æLLMå“åº”ä¸­çš„æœ‰æ•ˆç­–ç•¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
                strategies = self._generate_default_strategies(len(device_info))
            else:
                print(f"âœ… æˆåŠŸè§£æLLMç­–ç•¥: {len(strategies)}ä¸ªä»»åŠ¡çš„å¸è½½å†³ç­–")
                # æ‰“å°è§£æåˆ°çš„ç­–ç•¥æ¦‚è¦
                for i, strategy in enumerate(strategies):
                    task_id = strategy.get('task_id', i)
                    offload_ratio = strategy.get('offload_ratio', 0.0)
                    target_node = strategy.get('target_node', 0)
                    print(f"  ä»»åŠ¡{task_id}: å¸è½½æ¯”ä¾‹={offload_ratio:.2f}, ç›®æ ‡èŠ‚ç‚¹={target_node}")
            
            return strategies
            
        except Exception as e:
            print(f"\nâŒ LLMæœåŠ¡è°ƒç”¨å¤±è´¥: {e}")
            if self.use_mock:
                print("ğŸ”„ å¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼Œä½¿ç”¨è§„åˆ™ç”Ÿæˆç­–ç•¥ç»§ç»­è®­ç»ƒ...")
                # ç”Ÿæˆæ¨¡æ‹Ÿç­–ç•¥
                return self._generate_mock_strategies(env_state, device_info, edge_info, cloud_info)
            else:
                print("ğŸ”„ è¿”å›é»˜è®¤ç­–ç•¥...")
                return self._generate_default_strategies(len(device_info))

    def _generate_mock_strategies(self, env_state, device_info, edge_info, cloud_info):
        """åœ¨LLMæœåŠ¡ä¸å¯ç”¨æ—¶ç”Ÿæˆæ™ºèƒ½æ¨¡æ‹Ÿç­–ç•¥
        
        åŸºäºä»»åŠ¡ç‰¹å¾å’Œèµ„æºçŠ¶æ€ç”Ÿæˆåˆç†çš„å¸è½½ç­–ç•¥
        """
        print("ğŸ¤– ç”Ÿæˆæ™ºèƒ½æ¨¡æ‹Ÿå¸è½½ç­–ç•¥...")
        strategies = []
        
        # ç®€å•è§£æç¯å¢ƒçŠ¶æ€
        try:
            env_state_array = np.array(env_state)
            device_states = env_state_array[:len(device_info) * 4].reshape(len(device_info), 4)
            edge_states = env_state_array[len(device_info) * 4: len(device_info) * 4 + len(edge_info) * 3].reshape(len(edge_info), 3)
            cloud_states = env_state_array[len(device_info) * 4 + len(edge_info) * 3:len(device_info) * 4 + len(edge_info) * 3 + len(cloud_info) * 3].reshape(len(cloud_info), 3)
            task_states = env_state_array[len(device_info) * 4 + len(edge_info) * 3 + len(cloud_info) * 3:].reshape(len(device_info), 3)
        except:
            # å¼‚å¸¸æƒ…å†µä¸‹ä½¿ç”¨é»˜è®¤ç­–ç•¥
            print("âš ï¸ ç¯å¢ƒçŠ¶æ€è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
            return self._generate_default_strategies(len(device_info))
        
        print(f"ğŸ“Š åˆ†æ{len(device_info)}ä¸ªä»»åŠ¡çš„ç‰¹å¾...")
        
        # æ ¹æ®ä»»åŠ¡ç‰¹å¾å’Œèµ„æºçŠ¶æ€ç”Ÿæˆæ™ºèƒ½ç­–ç•¥
        for i in range(len(device_info)):
            device_battery = device_states[i][2] if len(device_states[i]) > 2 else 1.0  # ç”µæ± çŠ¶æ€
            task_computation = task_states[i][0]    # è®¡ç®—é‡ (MI)
            task_data_size = task_states[i][1]      # æ•°æ®é‡ (MB)
            task_deadline = task_states[i][2]       # æˆªæ­¢æ—¶é—´ (ç§’)
            
            # è®¡ç®—å¤„ç†æ—¶é—´ä¼°ç®—
            local_time = task_computation / 2.0     # æœ¬åœ°å¤„ç†æ—¶é—´ (2GHz)
            edge_time = task_computation / 8.0      # è¾¹ç¼˜å¤„ç†æ—¶é—´ (8GHz)
            cloud_time = task_computation / 32.0    # äº‘ç«¯å¤„ç†æ—¶é—´ (32GHz)
            
            # ç®€å•çš„ä¼ è¾“æ—¶é—´ä¼°ç®— (å‡è®¾ç½‘ç»œå¸¦å®½)
            edge_transmission = task_data_size / 50.0   # å‡è®¾50MB/såˆ°è¾¹ç¼˜
            cloud_transmission = task_data_size / 25.0  # å‡è®¾25MB/såˆ°äº‘ç«¯
            
            # å†³ç­–é€»è¾‘
            offload_ratio = 0.0
            target_node = 0  # é»˜è®¤æœ¬åœ°
            
            # å¦‚æœæœ¬åœ°å¤„ç†æ—¶é—´è¶…è¿‡æˆªæ­¢æ—¶é—´ï¼Œå¿…é¡»å¸è½½
            if local_time > task_deadline:
                # æ¯”è¾ƒè¾¹ç¼˜å’Œäº‘ç«¯çš„æ€»æ—¶é—´
                edge_total_time = edge_time + edge_transmission
                cloud_total_time = cloud_time + cloud_transmission
                
                if edge_total_time <= task_deadline and edge_total_time <= cloud_total_time:
                    # å¸è½½åˆ°è¾¹ç¼˜æœåŠ¡å™¨
                    offload_ratio = 1.0
                    target_node = (i % len(edge_info)) + 1  # è½®è¯¢åˆ†é…è¾¹ç¼˜æœåŠ¡å™¨
                    
                elif cloud_total_time <= task_deadline:
                    # å¸è½½åˆ°äº‘ç«¯
                    offload_ratio = 1.0
                    target_node = len(edge_info) + 1  # äº‘ç«¯èŠ‚ç‚¹
                    
                else:
                    # å³ä½¿è¶…æ—¶ä¹Ÿé€‰æ‹©æœ€å¿«çš„é€‰é¡¹
                    if cloud_total_time < edge_total_time:
                        offload_ratio = 1.0
                        target_node = len(edge_info) + 1  # äº‘ç«¯
                    else:
                        offload_ratio = 1.0
                        target_node = (i % len(edge_info)) + 1  # è¾¹ç¼˜
                        
            else:
                # æœ¬åœ°å¯ä»¥å®Œæˆï¼Œä½†è€ƒè™‘ç”µæ± çŠ¶æ€
                if device_battery < 0.2:  # ç”µæ± ä½äº20%
                    # éƒ¨åˆ†å¸è½½ä»¥èŠ‚çœç”µé‡
                    if task_computation > 500:  # è®¡ç®—å¯†é›†å‹ä»»åŠ¡
                        offload_ratio = 0.7
                        # é€‰æ‹©æ›´é«˜æ•ˆçš„ç›®æ ‡
                        if cloud_time + cloud_transmission < edge_time + edge_transmission:
                            target_node = len(edge_info) + 1  # äº‘ç«¯
                        else:
                            target_node = (i % len(edge_info)) + 1  # è¾¹ç¼˜
                    else:
                        offload_ratio = 0.3
                        target_node = (i % len(edge_info)) + 1  # è¾¹ç¼˜
                else:
                    # ç”µæ± å……è¶³ï¼Œå¯ä»¥è€ƒè™‘æœ¬åœ°å¤„ç†æˆ–è½»åº¦å¸è½½
                    if task_computation > 800:  # éå¸¸è®¡ç®—å¯†é›†
                        offload_ratio = 0.5
                        target_node = len(edge_info) + 1  # äº‘ç«¯
                    elif task_computation > 400:  # ä¸­ç­‰è®¡ç®—é‡
                        offload_ratio = 0.3
                        target_node = (i % len(edge_info)) + 1  # è¾¹ç¼˜
                    # else: ä¿æŒæœ¬åœ°å¤„ç† (offload_ratio = 0.0, target_node = 0)
            
            # ç¡®ä¿å€¼åœ¨åˆæ³•èŒƒå›´å†…
            offload_ratio = max(0.0, min(1.0, offload_ratio))
            target_node = max(0, min(len(edge_info) + len(cloud_info), target_node))
            
            strategy = {
                "task_id": i,
                "offload_ratio": round(offload_ratio, 2),
                "target_node": target_node
            }
            strategies.append(strategy)
            
            # æ‰“å°å†³ç­–ç†ç”±
            target_name = "æœ¬åœ°"
            if target_node >= 1 and target_node <= len(edge_info):
                target_name = f"è¾¹ç¼˜æœåŠ¡å™¨{target_node-1}"
            elif target_node > len(edge_info):
                target_name = "äº‘ç«¯"
                
            print(f"  ä»»åŠ¡{i}: è®¡ç®—é‡{task_computation:.0f}MI, æˆªæ­¢{task_deadline:.1f}s -> "
                  f"å¸è½½{offload_ratio:.2f}åˆ°{target_name}")
        
        print(f"âœ… ç”Ÿæˆ{len(strategies)}ä¸ªæ™ºèƒ½æ¨¡æ‹Ÿç­–ç•¥")
        return strategies

    def _extract_json_from_text(self, text):
        """ä»æ–‡æœ¬ä¸­æå–JSONå†…å®¹ï¼Œä½¿ç”¨å¤šç§ç­–ç•¥ç¡®ä¿è§£ææˆåŠŸ"""
        print(f"å¼€å§‹è§£æLLMå“åº”æ–‡æœ¬ï¼Œé•¿åº¦: {len(text)}å­—ç¬¦")
        
        # é¢„å¤„ç†ï¼šç§»é™¤å¯èƒ½çš„markdownæ ‡è®°å’Œå¤šä½™çš„ç©ºç™½
        text = text.strip()
        
        # ç­–ç•¥1: å°è¯•ç›´æ¥è§£ææ•´ä¸ªæ–‡æœ¬ä¸ºJSON
        try:
            result = json.loads(text)
            if isinstance(result, list):
                print("âœ… ç­–ç•¥1æˆåŠŸï¼šç›´æ¥è§£æä¸ºJSONæ•°ç»„")
                return result
            elif isinstance(result, dict):
                print("âœ… ç­–ç•¥1æˆåŠŸï¼šè§£æä¸ºå•ä¸ªJSONå¯¹è±¡ï¼Œè½¬æ¢ä¸ºæ•°ç»„")
                return [result]
        except:
            pass
        
        # ç­–ç•¥2: æŸ¥æ‰¾å¹¶æå– [...]  æ ¼å¼çš„JSONæ•°ç»„
        array_pattern = r'\[[\s\S]*?\]'
        array_matches = re.findall(array_pattern, text)
        
        for match in array_matches:
            try:
                result = json.loads(match)
                if isinstance(result, list):
                    print("âœ… ç­–ç•¥2æˆåŠŸï¼šæå–JSONæ•°ç»„æ ¼å¼")
                    return result
            except:
                continue
        
        # ç­–ç•¥3: æŸ¥æ‰¾å¹¶æå– {...} æ ¼å¼çš„JSONå¯¹è±¡
        object_pattern = r'\{[\s\S]*?\}'
        object_matches = re.findall(object_pattern, text)
        
        valid_objects = []
        for match in object_matches:
            try:
                obj = json.loads(match)
                if isinstance(obj, dict) and 'task_id' in obj:
                    valid_objects.append(obj)
            except:
                continue
        
        if valid_objects:
            print(f"âœ… ç­–ç•¥3æˆåŠŸï¼šæå–åˆ°{len(valid_objects)}ä¸ªJSONå¯¹è±¡")
            return valid_objects
        
        # ç­–ç•¥4: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç›´æ¥æå–å…³é”®ä¿¡æ¯
        pattern = r'task_id["\s]*:[\s]*(\d+)[\s\S]*?offload_ratio["\s]*:[\s]*([\d.]+)[\s\S]*?target_node["\s]*:[\s]*(\d+)'
        matches = re.findall(pattern, text, re.IGNORECASE)
        
        if matches:
            result = []
            for match in matches:
                try:
                    task_id = int(match[0])
                    offload_ratio = float(match[1])
                    target_node = int(match[2])
                    result.append({
                        "task_id": task_id,
                        "offload_ratio": offload_ratio,
                        "target_node": target_node
                    })
                except:
                    continue
            
            if result:
                print(f"âœ… ç­–ç•¥4æˆåŠŸï¼šé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå–{len(result)}ä¸ªç­–ç•¥")
                return result
        
        # ç­–ç•¥5: æŸ¥æ‰¾æ•°å­—åºåˆ—ï¼Œå°è¯•æ„å»ºç­–ç•¥
        lines = text.split('\n')
        result = []
        
        for line in lines:
            # æŸ¥æ‰¾åŒ…å«ä»»åŠ¡ä¿¡æ¯çš„è¡Œ
            task_match = re.search(r'ä»»åŠ¡(\d+).*?(\d+\.?\d*).*?(\d+)', line)
            if task_match:
                try:
                    task_id = int(task_match.group(1))
                    offload_ratio = float(task_match.group(2)) if '.' in task_match.group(2) else float(task_match.group(2)) / 10
                    target_node = int(task_match.group(3))
                    
                    # ç¡®ä¿å€¼åœ¨åˆç†èŒƒå›´å†…
                    if 0 <= offload_ratio <= 1 and 0 <= target_node <= 3:
                        result.append({
                            "task_id": task_id,
                            "offload_ratio": offload_ratio,
                            "target_node": target_node
                        })
                except:
                    continue
        
        if result:
            print(f"âœ… ç­–ç•¥5æˆåŠŸï¼šä»æ–‡æœ¬è¡Œä¸­æå–{len(result)}ä¸ªç­–ç•¥")
            return result
        
        print("âŒ æ‰€æœ‰è§£æç­–ç•¥å‡å¤±è´¥")
        return []
    
    def _generate_default_strategies(self, num_tasks):
        """ç”Ÿæˆé»˜è®¤å¸è½½ç­–ç•¥"""
        return [
            {
                "task_id": i,
                "offload_ratio": 0.0,
                "target_node": 0
            }
            for i in range(num_tasks)
        ]

    def _build_prompt(self, env_state, device_info, edge_info, cloud_info):
        """æ„å»ºç®€æ´æ˜ç¡®çš„æç¤ºæ¨¡æ¿ï¼Œè¦æ±‚ç›´æ¥è¿”å›JSON"""
        # å¯¼å…¥æç¤ºæ¨¡æ¿æ„å»ºå‡½æ•°
        try:
            from llm_assistant._build_prompt import build_prompt
            return build_prompt(env_state, device_info, edge_info, cloud_info)
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é‡æ–°è®¾è®¡çš„ç®€æ´æç¤ºæ¨¡æ¿
            print("ä½¿ç”¨é‡æ–°è®¾è®¡çš„ç®€æ´æç¤ºæ¨¡æ¿")
            
            # è§£æç¯å¢ƒçŠ¶æ€
            try:
                env_state_array = np.array(env_state)
                device_states = env_state_array[:len(device_info) * 4].reshape(len(device_info), 4)
                edge_states = env_state_array[len(device_info) * 4: len(device_info) * 4 + len(edge_info) * 3].reshape(len(edge_info), 3)
                cloud_states = env_state_array[len(device_info) * 4 + len(edge_info) * 3:len(device_info) * 4 + len(edge_info) * 3 + len(cloud_info) * 3].reshape(len(cloud_info), 3)
                task_states = env_state_array[len(device_info) * 4 + len(edge_info) * 3 + len(cloud_info) * 3:].reshape(len(device_info), 3)
            except Exception as e:
                print(f"è§£æç¯å¢ƒçŠ¶æ€å¤±è´¥: {e}")
                # ä½¿ç”¨ç®€å•æ–¹å¼å¤„ç†
                device_states = np.zeros((len(device_info), 4))
                edge_states = np.zeros((len(edge_info), 3))
                cloud_states = np.zeros((len(cloud_info), 3))
                task_states = np.zeros((len(device_info), 3))
                
            # æ„å»ºæç®€çš„æç¤ºæ¨¡æ¿
            prompt = f"""ä½œä¸ºäº‘è¾¹ç«¯è®¡ç®—ä¸“å®¶ï¼Œä¸ºä»¥ä¸‹{len(device_info)}ä¸ªä»»åŠ¡åˆ¶å®šå¸è½½ç­–ç•¥ã€‚

ç¯å¢ƒ:
- ç»ˆç«¯è®¾å¤‡: {len(device_info)}ä¸ªï¼Œ2.0GHz CPUï¼Œç”µæ± 1%
- è¾¹ç¼˜æœåŠ¡å™¨: {len(edge_info)}ä¸ªï¼Œ8.0GHz CPU  
- äº‘æœåŠ¡å™¨: {len(cloud_info)}ä¸ªï¼Œ32.0GHz CPU

ä»»åŠ¡ä¿¡æ¯:"""

            for i, state in enumerate(task_states):
                computation = f"{state[0]:.1f}MI"
                data_size = f"{state[1]:.1f}MB"
                deadline = f"{state[2]:.1f}s"
                prompt += f"\nä»»åŠ¡{i}: {computation}, {data_size}, æœŸé™{deadline}"

            prompt += f"""

è§„åˆ™:
- offload_ratio: 0=æœ¬åœ°æ‰§è¡Œ, 1=å®Œå…¨å¸è½½
- target_node: 0=æœ¬åœ°, 1-{len(edge_info)}=è¾¹ç¼˜æœåŠ¡å™¨, {len(edge_info)+1}=äº‘æœåŠ¡å™¨

è¦æ±‚: ç›´æ¥è¿”å›JSONæ•°ç»„ï¼Œæ— éœ€è§£é‡Šã€‚æ ¼å¼:

[{{"task_id":0,"offload_ratio":0.8,"target_node":1}},{{"task_id":1,"offload_ratio":1.0,"target_node":3}}]

JSON:"""

            return prompt