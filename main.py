#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM+MADDPG äº‘è¾¹ç«¯è®¡ç®—å¸è½½ç³»ç»Ÿ
ç»Ÿä¸€å…¥å£æ–‡ä»¶ - æ”¯æŒå®Œæ•´çš„è®­ç»ƒã€æµ‹è¯•ã€å¯¹æ¯”åŠŸèƒ½
"""

import os
import sys
import json
import time
import yaml
import random
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple
import torch

# å¯¼å…¥è®­ç»ƒå’Œæµ‹è¯•æ¨¡å—
from experiments.train_llm_maddpg_complete import train_llm_maddpg_complete
from experiments.train_maddpg import train_maddpg
from experiments.train_llm import train_llm
from experiments.test_llm_maddpg import test_llm_maddpg
from experiments.test_maddpg import test_maddpg
from experiments.test_llm import test_llm
from utils.config import load_config
from utils.path_manager import PathManager, create_new_experiment


def setup_gpu(gpu_id=None):
    """è®¾ç½®GPUç¯å¢ƒ"""
    if gpu_id is not None and torch.cuda.is_available():
        if gpu_id < torch.cuda.device_count():
            torch.cuda.set_device(gpu_id)
            os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
            print(f"âœ… GPUè®¾ç½®æˆåŠŸ: GPU {gpu_id} - {torch.cuda.get_device_name(gpu_id)}")
            return gpu_id
        else:
            print(f"âŒ GPU {gpu_id} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤GPU 0")
            gpu_id = 0
            torch.cuda.set_device(0)
            os.environ['CUDA_VISIBLE_DEVICES'] = "0"
            return gpu_id
    elif torch.cuda.is_available():
        print(f"ğŸ”§ ä½¿ç”¨é»˜è®¤GPU: {torch.cuda.get_device_name(0)}")
        return 0
    else:
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
        return None


def print_gpu_info():
    """æ‰“å°GPUä¿¡æ¯"""
    if torch.cuda.is_available():
        print(f"\nğŸ® GPUç¯å¢ƒä¿¡æ¯:")
        print(f"  PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"  CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"  GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
        
        # æ˜¾ç¤ºå½“å‰GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
        current_gpu = torch.cuda.current_device()
        memory_allocated = torch.cuda.memory_allocated(current_gpu) / 1024**3
        memory_cached = torch.cuda.memory_reserved(current_gpu) / 1024**3
        print(f"  å½“å‰GPU {current_gpu} å†…å­˜: {memory_allocated:.2f}GB / {memory_cached:.2f}GB (å·²åˆ†é…/å·²ç¼“å­˜)")
    else:
        print(f"\nâš ï¸  GPUä¸å¯ç”¨:")
        print(f"  PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"  å°†ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")


def set_seed(seed):
    """è®¾ç½®éšæœºç§å­ç¡®ä¿å¯å¤ç°æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def print_banner():
    """æ‰“å°é¡¹ç›®å¯åŠ¨æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  LLM+MADDPG äº‘è¾¹ç«¯è®¡ç®—å¸è½½ç³»ç»Ÿ                 â•‘
â•‘                        ç»Ÿä¸€è®­ç»ƒæµ‹è¯•å¹³å°                       â•‘
â•‘                                                              â•‘
â•‘  æ”¯æŒç®—æ³•ï¼š                                                    â•‘
â•‘  â€¢ LLM+MADDPGï¼ˆå®Œæ•´ç‰ˆï¼‰- æ¯stepå’¨è¯¢LLM + çŸ¥è¯†è’¸é¦              â•‘
â•‘  â€¢ çº¯MADDPG - å¤šæ™ºèƒ½ä½“æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦                          â•‘
â•‘  â€¢ çº¯LLM - å¤§è¯­è¨€æ¨¡å‹ç›´æ¥å†³ç­–                                  â•‘
â•‘                                                              â•‘
â•‘  åŠŸèƒ½ï¼šè®­ç»ƒ â†’ æµ‹è¯• â†’ æ€§èƒ½å¯¹æ¯” â†’ ç»“æœå¯è§†åŒ–                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)


def train_llm_maddpg_algorithm(path_manager, config):
    """è®­ç»ƒLLM+MADDPGå®Œæ•´ç‰ˆ"""
    print("\n" + "="*80)
    print("ğŸš€ è®­ç»ƒ LLM+MADDPGï¼ˆå®Œæ•´ç‰ˆï¼‰")
    print("="*80)
    
    try:
        # è®­ç»ƒ
        start_time = time.time()
        results = train_llm_maddpg_complete("config.yaml")
        training_time = time.time() - start_time
        
        # ä¿å­˜ç»“æœæ‘˜è¦
        results['training_time'] = training_time
        results['algorithm'] = 'LLM+MADDPG'
        
        result_file = path_manager.get_algorithm_result_file_path("llm_maddpg", "training_summary.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… LLM+MADDPGè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
        print(f"ğŸ’¾ ç»“æœä¿å­˜è‡³: {result_file}")
        
        return results
        
    except Exception as e:
        print(f"âŒ LLM+MADDPGè®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {}


def train_pure_algorithms(path_manager, config):
    """è®­ç»ƒçº¯MADDPGå’Œçº¯LLMç®—æ³•"""
    results = {}
    
    # è®­ç»ƒçº¯MADDPG
    print("\n" + "="*80)
    print("ğŸ”¥ è®­ç»ƒ çº¯MADDPG")
    print("="*80)
    
    try:
        start_time = time.time()
        maddpg_result = train_maddpg(config)
        training_time = time.time() - start_time
        
        results['maddpg'] = {
            'training_time': training_time,
            'algorithm': 'MADDPG',
            'result': maddpg_result
        }
        
        result_file = path_manager.get_algorithm_result_file_path("maddpg", "training_summary.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results['maddpg'], f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… çº¯MADDPGè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
        
    except Exception as e:
        print(f"âŒ çº¯MADDPGè®­ç»ƒå¤±è´¥: {e}")
        results['maddpg'] = {'error': str(e)}
    
    # è®­ç»ƒçº¯LLM
    print("\n" + "="*80)
    print("ğŸ§  è®­ç»ƒ çº¯LLM")
    print("="*80)
    
    try:
        start_time = time.time()
        llm_result = train_llm(config)
        training_time = time.time() - start_time
        
        results['llm'] = {
            'training_time': training_time,
            'algorithm': 'LLM',
            'result': llm_result
        }
        
        result_file = path_manager.get_algorithm_result_file_path("llm", "training_summary.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results['llm'], f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… çº¯LLMè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
        
    except Exception as e:
        print(f"âŒ çº¯LLMè®­ç»ƒå¤±è´¥: {e}")
        results['llm'] = {'error': str(e)}
    
    return results


def run_algorithm_tests(path_manager, config):
    """è¿è¡Œç®—æ³•æµ‹è¯•"""
    print("\n" + "="*80)
    print("ğŸ§ª å¼€å§‹ç®—æ³•æ€§èƒ½æµ‹è¯•")
    print("="*80)
    
    test_results = {}
    
    # æµ‹è¯•LLM+MADDPG (çº¯Agentæ¨¡å¼ï¼Œä¸ä½¿ç”¨LLMæŒ‡å¯¼)
    try:
        print("ğŸ”¬ æµ‹è¯• LLM+MADDPG (çº¯Agentæ¨¡å¼)...")
        print("  ğŸ“‹ è¯´æ˜: æµ‹è¯•ç»è¿‡LLM+MADDPGè®­ç»ƒçš„Agentåœ¨æ— LLMæŒ‡å¯¼ä¸‹çš„è¡¨ç°")
        llm_maddpg_metrics = test_llm_maddpg()
        if isinstance(llm_maddpg_metrics, tuple) and len(llm_maddpg_metrics) == 3:
            energy, util, delay = llm_maddpg_metrics
            test_results['llm_maddpg_pure_agent'] = {
                'energy': np.mean(energy) if energy else 0,
                'utilization': np.mean(util) if util else 0,
                'delay': np.mean(delay) if delay else 0,
                'energy_std': np.std(energy) if energy else 0,
                'utilization_std': np.std(util) if util else 0,
                'delay_std': np.std(delay) if delay else 0,
            }
            print(f"  âœ… èƒ½è€—: {test_results['llm_maddpg_pure_agent']['energy']:.4f}, "
                  f"æ—¶å»¶: {test_results['llm_maddpg_pure_agent']['delay']:.4f}")
    except Exception as e:
        print(f"  âŒ LLM+MADDPGçº¯Agentæµ‹è¯•å¤±è´¥: {e}")

    # æµ‹è¯•çº¯MADDPG
    try:
        print("\nğŸ”¬ æµ‹è¯• çº¯MADDPG...")
        maddpg_metrics = test_maddpg()
        if isinstance(maddpg_metrics, tuple) and len(maddpg_metrics) == 3:
            energy, util, delay = maddpg_metrics
            test_results['maddpg'] = {
                'energy': np.mean(energy) if energy else 0,
                'utilization': np.mean(util) if util else 0,
                'delay': np.mean(delay) if delay else 0,
                'energy_std': np.std(energy) if energy else 0,
                'utilization_std': np.std(util) if util else 0,
                'delay_std': np.std(delay) if delay else 0,
            }
            print(f"  âœ… èƒ½è€—: {test_results['maddpg']['energy']:.4f}, "
                  f"æ—¶å»¶: {test_results['maddpg']['delay']:.4f}")
    except Exception as e:
        print(f"  âŒ çº¯MADDPGæµ‹è¯•å¤±è´¥: {e}")

    # æµ‹è¯•çº¯LLM
    try:
        print("\nğŸ”¬ æµ‹è¯• çº¯LLM...")
        llm_metrics = test_llm()
        if isinstance(llm_metrics, tuple) and len(llm_metrics) == 3:
            energy, util, delay = llm_metrics
            test_results['llm'] = {
                'energy': np.mean(energy) if energy else 0,
                'utilization': np.mean(util) if util else 0,
                'delay': np.mean(delay) if delay else 0,
                'energy_std': np.std(energy) if energy else 0,
                'utilization_std': np.std(util) if util else 0,
                'delay_std': np.std(delay) if delay else 0,
            }
            print(f"  âœ… èƒ½è€—: {test_results['llm']['energy']:.4f}, "
                  f"æ—¶å»¶: {test_results['llm']['delay']:.4f}")
    except Exception as e:
        print(f"  âŒ çº¯LLMæµ‹è¯•å¤±è´¥: {e}")
    
    return test_results


def generate_comparison_report(training_results, test_results, path_manager):
    """ç”Ÿæˆç®—æ³•å¯¹æ¯”æŠ¥å‘Š"""
    print("\n" + "="*80)
    print("ğŸ“Š ç”Ÿæˆç®—æ³•å¯¹æ¯”æŠ¥å‘Š")
    print("="*80)
    
    # åˆå¹¶è®­ç»ƒå’Œæµ‹è¯•ç»“æœ
    comparison_data = []
    
    algorithms = ['llm_maddpg', 'maddpg', 'llm']
    algorithm_names = ['LLM+MADDPG', 'MADDPG', 'LLM']
    
    for algo, name in zip(algorithms, algorithm_names):
        row = {'Algorithm': name}
        
        # æ·»åŠ è®­ç»ƒç»“æœ
        if algo in training_results and 'result' in training_results[algo]:
            train_data = training_results[algo]['result']
            if isinstance(train_data, dict):
                row['Training_Time'] = training_results[algo].get('training_time', 0)
                row['Final_Reward'] = np.mean(train_data.get('episode_rewards', [0])[-50:]) if train_data.get('episode_rewards') else 0
                row['Total_Episodes'] = len(train_data.get('episode_rewards', []))
        
        # æ·»åŠ æµ‹è¯•ç»“æœ
        test_key = f"{algo}_pure_agent" if algo == 'llm_maddpg' else algo
        if test_key in test_results:
            test_data = test_results[test_key]
            row['Test_Energy'] = test_data.get('energy', 0)
            row['Test_Utilization'] = test_data.get('utilization', 0)
            row['Test_Delay'] = test_data.get('delay', 0)
            row['Energy_Std'] = test_data.get('energy_std', 0)
            row['Utilization_Std'] = test_data.get('utilization_std', 0)
            row['Delay_Std'] = test_data.get('delay_std', 0)
        
        comparison_data.append(row)
    
    # åˆ›å»ºDataFrameå¹¶ä¿å­˜
    if comparison_data:
        df = pd.DataFrame(comparison_data)
        
        # ä¿å­˜åˆ°CSV
        comparison_file = path_manager.get_comparison_file_path("algorithm_comparison.csv")
        df.to_csv(comparison_file, index=False, encoding='utf-8-sig')
        
        # ä¿å­˜åˆ°JSON
        json_file = path_manager.get_comparison_file_path("algorithm_comparison.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(comparison_data, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… å¯¹æ¯”æŠ¥å‘Šä¿å­˜è‡³: {comparison_file}")
        print(f"âœ… è¯¦ç»†æ•°æ®ä¿å­˜è‡³: {json_file}")
        
        # æ‰“å°å¯¹æ¯”ç»“æœ
        print("\nğŸ“‹ ç®—æ³•æ€§èƒ½å¯¹æ¯”:")
        print("-" * 80)
        for _, row in df.iterrows():
            print(f"{row['Algorithm']}:")
            print(f"  èƒ½è€—: {row.get('Test_Energy', 0):.4f} Â± {row.get('Energy_Std', 0):.4f}")
            print(f"  åˆ©ç”¨ç‡: {row.get('Test_Utilization', 0):.4f} Â± {row.get('Utilization_Std', 0):.4f}")
            print(f"  æ—¶å»¶: {row.get('Test_Delay', 0):.4f} Â± {row.get('Delay_Std', 0):.4f}")
            if 'Training_Time' in row:
                print(f"  è®­ç»ƒæ—¶é—´: {row.get('Training_Time', 0):.2f}ç§’")
            print()


def create_comparison_plots(test_results, path_manager):
    """åˆ›å»ºå¯¹æ¯”å›¾è¡¨"""
    print("ğŸ“Š ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    
    if not test_results:
        print("  âš ï¸  æ²¡æœ‰æµ‹è¯•ç»“æœï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
        return
    
    try:
        # å‡†å¤‡æ•°æ®
        algorithms = []
        energies = []
        utilizations = []
        delays = []
        
        for algo, data in test_results.items():
            if algo == 'llm_maddpg_pure_agent':
                algorithms.append('LLM+MADDPG\n(Pure Agent)')
            elif algo == 'maddpg':
                algorithms.append('MADDPG')
            elif algo == 'llm':
                algorithms.append('LLM')
            else:
                continue
                
            energies.append(data.get('energy', 0))
            utilizations.append(data.get('utilization', 0))
            delays.append(data.get('delay', 0))
        
        if len(algorithms) > 0:
            # åˆ›å»ºå¯¹æ¯”å›¾è¡¨
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            
            # èƒ½è€—å¯¹æ¯”
            axes[0].bar(algorithms, energies, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
            axes[0].set_title('å¹³å‡èƒ½è€—å¯¹æ¯”')
            axes[0].set_ylabel('èƒ½è€— (J)')
            axes[0].tick_params(axis='x', rotation=45)
            
            # èµ„æºåˆ©ç”¨ç‡å¯¹æ¯”
            axes[1].bar(algorithms, utilizations, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
            axes[1].set_title('å¹³å‡èµ„æºåˆ©ç”¨ç‡å¯¹æ¯”')
            axes[1].set_ylabel('åˆ©ç”¨ç‡')
            axes[1].tick_params(axis='x', rotation=45)
            
            # æ—¶å»¶å¯¹æ¯”
            axes[2].bar(algorithms, delays, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
            axes[2].set_title('å¹³å‡ä»»åŠ¡æ—¶å»¶å¯¹æ¯”')
            axes[2].set_ylabel('æ—¶å»¶ (s)')
            axes[2].tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            plot_file = path_manager.get_plot_file_path("algorithm_comparison.png")
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"  âœ… å¯¹æ¯”å›¾è¡¨ä¿å­˜è‡³: {plot_file}")
        
    except Exception as e:
        print(f"  âŒ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='LLM+MADDPGäº‘è¾¹ç«¯è®¡ç®—å¸è½½ç³»ç»Ÿ - æœåŠ¡å™¨è®­ç»ƒç‰ˆ')
    
    # è¿è¡Œæ¨¡å¼
    parser.add_argument('--mode', choices=['all', 'train_only', 'test_only', 'llm_maddpg_only', 
                                          'maddpg_only', 'llm_only', 'test_maddpg_only', 
                                          'test_llm_maddpg_only', 'test_llm_only'], 
                       default='all', help='è¿è¡Œæ¨¡å¼')
    
    # GPUè®¾ç½®
    parser.add_argument('--gpu', type=int, default=None, help='æŒ‡å®šGPU ID (é»˜è®¤: è‡ªåŠ¨é€‰æ‹©)')
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--episodes', type=int, default=None, help='è®­ç»ƒè½®æ•° (é»˜è®¤: ä½¿ç”¨é…ç½®æ–‡ä»¶)')
    # æ–‡ä»¶è®¾ç½®
    parser.add_argument('--config', default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    # æœåŠ¡å™¨æ¨¡å¼è®¾ç½®
    parser.add_argument('--server-mode', action='store_true', help='æœåŠ¡å™¨æ¨¡å¼: æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯å’Œè¿›åº¦')
    parser.add_argument('--batch-train', action='store_true', help='æ‰¹é‡è®­ç»ƒ: æŒ‰é¡ºåºè®­ç»ƒæ‰€æœ‰ç®—æ³•')
    # æ¨¡å‹è·¯å¾„
    parser.add_argument('--model-path', type=str, default=None, help='æŒ‡å®šæµ‹è¯•æ—¶åŠ è½½çš„æ¨¡å‹ç›®å½•')
    args = parser.parse_args()
    
    # æ‰“å°å¯åŠ¨æ¨ªå¹…
    print_banner()
    
    # è®¾ç½®GPUç¯å¢ƒ
    if args.server_mode or args.gpu is not None:
        print_gpu_info()
    
    gpu_id = setup_gpu(args.gpu)
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)

    # åŠ è½½é…ç½®
    config = load_config(args.config)

    # å¦‚æœæŒ‡å®šäº†è®­ç»ƒè½®æ•°ï¼Œæ›´æ–°é…ç½®
    if args.episodes is not None:
        if 'training' not in config:
            config['training'] = {}
        config['training']['episodes'] = args.episodes
        print(f"ğŸ”§ è®­ç»ƒè½®æ•°è®¾ç½®ä¸º: {args.episodes}")
    
    # åˆ›å»ºæ–°çš„å®éªŒè·¯å¾„ç®¡ç†å™¨
    path_manager = create_new_experiment()
    
    print(f"\nğŸ—‚ï¸  å®éªŒé…ç½®:")
    print(f"  è¿è¡Œæ¨¡å¼: {args.mode}")
    if gpu_id is not None:
        print(f"  ä½¿ç”¨GPU: {gpu_id}")
    else:
        print(f"  ä½¿ç”¨è®¾å¤‡: CPU")
    print(f"  é…ç½®æ–‡ä»¶: {args.config}")
    print(f"  éšæœºç§å­: {args.seed}")
    if args.episodes:
        print(f"  è®­ç»ƒè½®æ•°: {args.episodes}")
    print(f"  å®éªŒç›®å½•: {path_manager.get_experiment_dir()}")
    print(f"  æ—¶é—´æˆ³: {path_manager.experiment_timestamp}")
    
    # æœåŠ¡å™¨æ¨¡å¼æ˜¾ç¤ºè¯¦ç»†ç›®å½•ç»“æ„
    if args.server_mode:
        print("\nğŸ“ ç›®å½•ç»“æ„:")
        dir_info = path_manager.get_directory_info()
        for key, path in dir_info.items():
            if key != 'experiment_timestamp':
                print(f"  {key}: {path}")
    
    training_results = {}
    test_results = {}
    
    try:
        # æ‰¹é‡è®­ç»ƒæ¨¡å¼
        if args.batch_train or args.mode == 'all':
            print(f"\n{'='*100}")
            print("ğŸš€ æœåŠ¡å™¨æ‰¹é‡è®­ç»ƒæ¨¡å¼")
            print(f"{'='*100}")
            
            # æŒ‰é¡ºåºè®­ç»ƒæ‰€æœ‰ç®—æ³•
            algorithms = ['maddpg', 'llm_maddpg', 'llm']
            
            print("ğŸ“‹ è®­ç»ƒè®¡åˆ’:")
            for i, algo in enumerate(algorithms, 1):
                print(f"  {i}. {algo.upper()}")
            print()
            
            for i, algo in enumerate(algorithms, 1):
                print(f"\n{'='*80}")
                print(f"ğŸ”¥ æ­¥éª¤ {i}/3: è®­ç»ƒ {algo.upper()}")
                print(f"{'='*80}")
                
                if algo == 'maddpg':
                    # è®­ç»ƒçº¯MADDPG
                    try:
                        start_time = time.time()
                        maddpg_result = train_maddpg(config)
                        training_time = time.time() - start_time
                        
                        training_results['maddpg'] = {
                            'training_time': training_time,
                            'algorithm': 'MADDPG',
                            'result': maddpg_result
                        }
                        
                        result_file = path_manager.get_algorithm_result_file_path("maddpg", "training_summary.json")
                        with open(result_file, 'w', encoding='utf-8') as f:
                            json.dump(training_results['maddpg'], f, indent=2, ensure_ascii=False, default=str)
                        
                        print(f"âœ… {algo.upper()} è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
                        
                        if args.server_mode:
                            print(f"ğŸ˜´ ä¼‘æ¯10ç§’åç»§ç»­ä¸‹ä¸€ä¸ªç®—æ³•...")
                            time.sleep(10)
                            
                    except Exception as e:
                        print(f"âŒ {algo.upper()} è®­ç»ƒå¤±è´¥: {e}")
                        training_results['maddpg'] = {'error': str(e)}
                
                elif algo == 'llm_maddpg':
                    # è®­ç»ƒLLM+MADDPG
                    try:
                        start_time = time.time()
                        results = train_llm_maddpg_complete("config.yaml")
                        training_time = time.time() - start_time
                        
                        results['training_time'] = training_time
                        results['algorithm'] = 'LLM+MADDPG'
                        
                        result_file = path_manager.get_algorithm_result_file_path("llm_maddpg", "training_summary.json")
                        with open(result_file, 'w', encoding='utf-8') as f:
                            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
                        
                        training_results['llm_maddpg'] = results
                        print(f"âœ… {algo.upper()} è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
                        
                        if args.server_mode:
                            print(f"ğŸ˜´ ä¼‘æ¯10ç§’åç»§ç»­ä¸‹ä¸€ä¸ªç®—æ³•...")
                            time.sleep(10)
                            
                    except Exception as e:
                        print(f"âŒ {algo.upper()} è®­ç»ƒå¤±è´¥: {e}")
                        training_results['llm_maddpg'] = {'error': str(e)}
                
                elif algo == 'llm':
                    # è®­ç»ƒçº¯LLM
                    try:
                        start_time = time.time()
                        llm_result = train_llm(config)
                        training_time = time.time() - start_time
                        
                        training_results['llm'] = {
                            'training_time': training_time,
                            'algorithm': 'LLM',
                            'result': llm_result
                        }
                        
                        result_file = path_manager.get_algorithm_result_file_path("llm", "training_summary.json")
                        with open(result_file, 'w', encoding='utf-8') as f:
                            json.dump(training_results['llm'], f, indent=2, ensure_ascii=False, default=str)
                        
                        print(f"âœ… {algo.upper()} è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
                        
                    except Exception as e:
                        print(f"âŒ {algo.upper()} è®­ç»ƒå¤±è´¥: {e}")
                        training_results['llm'] = {'error': str(e)}
            
            # æ‰¹é‡æµ‹è¯•
            if args.mode == 'all':
                print(f"\n{'='*100}")
                print("ğŸ§ª æœåŠ¡å™¨æ‰¹é‡æµ‹è¯•æ¨¡å¼")
                print(f"{'='*100}")
                
                test_results = run_algorithm_tests(path_manager, config)
        
        else:
            # å•ç‹¬è®­ç»ƒæ¨¡å¼é€»è¾‘
            print(f"\n{'='*80}")
            print("ğŸ¯ å•ç‹¬ç®—æ³•è®­ç»ƒæ¨¡å¼")
            print(f"{'='*80}")
            
            if args.mode == 'llm_maddpg_only':
                print("ğŸš€ è®­ç»ƒ LLM+MADDPGï¼ˆå®Œæ•´ç‰ˆï¼‰")
                print("="*80)
                try:
                    start_time = time.time()
                    results = train_llm_maddpg_complete("config.yaml")
                    training_time = time.time() - start_time
                    
                    results['training_time'] = training_time
                    results['algorithm'] = 'LLM+MADDPG'
                    
                    result_file = path_manager.get_algorithm_result_file_path("llm_maddpg", "training_summary.json")
                    with open(result_file, 'w', encoding='utf-8') as f:
                        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
                    
                    training_results['llm_maddpg'] = results
                    print(f"âœ… LLM+MADDPGè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
                    
                except Exception as e:
                    print(f"âŒ LLM+MADDPGè®­ç»ƒå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    training_results['llm_maddpg'] = {'error': str(e)}
            
            elif args.mode == 'maddpg_only':
                print("ğŸ”¥ è®­ç»ƒ çº¯MADDPG")
                print("="*80)
                try:
                    start_time = time.time()
                    maddpg_result = train_maddpg(config)
                    training_time = time.time() - start_time
                    
                    training_results['maddpg'] = {
                        'training_time': training_time,
                        'algorithm': 'MADDPG',
                        'result': maddpg_result
                    }
                    
                    result_file = path_manager.get_algorithm_result_file_path("maddpg", "training_summary.json")
                    with open(result_file, 'w', encoding='utf-8') as f:
                        json.dump(training_results['maddpg'], f, indent=2, ensure_ascii=False, default=str)
                    
                    print(f"âœ… çº¯MADDPGè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
                    
                except Exception as e:
                    print(f"âŒ çº¯MADDPGè®­ç»ƒå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    training_results['maddpg'] = {'error': str(e)}
            
            elif args.mode == 'llm_only':
                print("ğŸ§  è®­ç»ƒ çº¯LLM")
                print("="*80)
                try:
                    start_time = time.time()
                    llm_result = train_llm(config)
                    training_time = time.time() - start_time
                    
                    training_results['llm'] = {
                        'training_time': training_time,
                        'algorithm': 'LLM',
                        'result': llm_result
                    }
                    
                    result_file = path_manager.get_algorithm_result_file_path("llm", "training_summary.json")
                    with open(result_file, 'w', encoding='utf-8') as f:
                        json.dump(training_results['llm'], f, indent=2, ensure_ascii=False, default=str)
                    
                    print(f"âœ… çº¯LLMè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
                    
                except Exception as e:
                    print(f"âŒ çº¯LLMè®­ç»ƒå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    training_results['llm'] = {'error': str(e)}
            
            # åŸæœ‰çš„å¤åˆæ¨¡å¼ï¼ˆallã€train_onlyç­‰ï¼‰
            elif args.mode in ['all', 'train_only']:
                print(f"ğŸ¯ å¼€å§‹è®­ç»ƒé˜¶æ®µ")
                print(f"{'='*80}")
                
                if args.mode == 'all' or args.mode == 'llm_maddpg_only':
                    # è®­ç»ƒLLM+MADDPG
                    llm_maddpg_result = train_llm_maddpg_algorithm(path_manager, config)
                    if llm_maddpg_result:
                        training_results['llm_maddpg'] = llm_maddpg_result
                
                if args.mode == 'all' or args.mode == 'maddpg_only' or args.mode == 'llm_only':
                    # è®­ç»ƒå…¶ä»–ç®—æ³•
                    pure_results = train_pure_algorithms(path_manager, config)
                    training_results.update(pure_results)
            
            # æµ‹è¯•é˜¶æ®µ
            if args.mode in ['all', 'test_only', 'test_maddpg_only', 'test_llm_maddpg_only', 'test_llm_only']:
                print(f"\n{'='*80}")
                print("ğŸ¯ å¼€å§‹æµ‹è¯•é˜¶æ®µ")
                print(f"{'='*80}")
                
                # å¤„ç†å•ç‹¬æµ‹è¯•ç‰¹å®šç®—æ³•çš„æƒ…å†µ
                if args.mode == 'test_maddpg_only':
                    print("\nğŸ”¬ ä»…æµ‹è¯• çº¯MADDPG...")
                    try:
                        maddpg_metrics = test_maddpg(model_path=args.model_path)
                        if isinstance(maddpg_metrics, tuple) and len(maddpg_metrics) == 3:
                            energy, util, delay = maddpg_metrics
                            test_results['maddpg'] = {
                                'energy': np.mean(energy) if energy else 0,
                                'utilization': np.mean(util) if util else 0,
                                'delay': np.mean(delay) if delay else 0,
                                'energy_std': np.std(energy) if energy else 0,
                                'utilization_std': np.std(util) if util else 0,
                                'delay_std': np.std(delay) if delay else 0,
                            }
                            print(f"  âœ… èƒ½è€—: {test_results['maddpg']['energy']:.4f}, "
                                  f"æ—¶å»¶: {test_results['maddpg']['delay']:.4f}")
                    except Exception as e:
                        print(f"  âŒ çº¯MADDPGæµ‹è¯•å¤±è´¥: {e}")
                elif args.mode == 'test_llm_maddpg_only':
                    print("\nğŸ”¬ ä»…æµ‹è¯• LLM+MADDPG (çº¯Agent)...")
                    try:
                        llm_maddpg_metrics = test_llm_maddpg(model_path=args.model_path)
                        if isinstance(llm_maddpg_metrics, tuple) and len(llm_maddpg_metrics) == 3:
                            energy, util, delay = llm_maddpg_metrics
                            test_results['llm_maddpg_pure_agent'] = {
                                'energy': np.mean(energy) if energy else 0,
                                'utilization': np.mean(util) if util else 0,
                                'delay': np.mean(delay) if delay else 0,
                                'energy_std': np.std(energy) if energy else 0,
                                'utilization_std': np.std(util) if util else 0,
                                'delay_std': np.std(delay) if delay else 0,
                            }
                            print(f"  âœ… èƒ½è€—: {test_results['llm_maddpg_pure_agent']['energy']:.4f}, "
                                  f"æ—¶å»¶: {test_results['llm_maddpg_pure_agent']['delay']:.4f}")
                    except Exception as e:
                        print(f"  âŒ LLM+MADDPGçº¯Agentæµ‹è¯•å¤±è´¥: {e}")
                elif args.mode == 'test_llm_only':
                    print("\nğŸ”¬ ä»…æµ‹è¯• çº¯LLM...")
                    try:
                        llm_metrics = test_llm(model_path=args.model_path)
                        if isinstance(llm_metrics, tuple) and len(llm_metrics) == 3:
                            energy, util, delay = llm_metrics
                            test_results['llm'] = {
                                'energy': np.mean(energy) if energy else 0,
                                'utilization': np.mean(util) if util else 0,
                                'delay': np.mean(delay) if delay else 0,
                                'energy_std': np.std(energy) if energy else 0,
                                'utilization_std': np.std(util) if util else 0,
                                'delay_std': np.std(delay) if delay else 0,
                            }
                            print(f"  âœ… èƒ½è€—: {test_results['llm']['energy']:.4f}, "
                                  f"æ—¶å»¶: {test_results['llm']['delay']:.4f}")
                    except Exception as e:
                        print(f"  âŒ çº¯LLMæµ‹è¯•å¤±è´¥: {e}")
                else:
                    # é»˜è®¤æ‰¹é‡æµ‹è¯•
                    test_results = run_algorithm_tests(path_manager, config)
        
        # å¯¹æ¯”åˆ†æ
        if args.mode == 'all' and (training_results or test_results):
            print(f"\n{'='*80}")
            print("ğŸ¯ å¼€å§‹å¯¹æ¯”åˆ†æ")
            print(f"{'='*80}")
            
            generate_comparison_report(training_results, test_results, path_manager)
            create_comparison_plots(test_results, path_manager)
        
        # ä¿å­˜å®Œæ•´å®éªŒè®°å½•
        experiment_summary = {
            'experiment_timestamp': path_manager.experiment_timestamp,
            'mode': args.mode,
            'gpu_id': gpu_id,
            'episodes': args.episodes,
            'config_file': args.config,
            'seed': args.seed,
            'server_mode': args.server_mode,
            'batch_train': args.batch_train,
            'training_results': training_results,
            'test_results': test_results,
            'directory_structure': path_manager.get_directory_info()
        }
        
        summary_file = path_manager.get_experiment_dir() + "/experiment_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(experiment_summary, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nğŸ‰ å®éªŒå®Œæˆï¼")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {path_manager.get_experiment_dir()}")
        print(f"ğŸ“„ å®éªŒæ‘˜è¦: {summary_file}")
        
        if args.server_mode:
            print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            success_count = len([r for r in training_results.values() if 'error' not in r])
            total_count = len(training_results)
            print(f"  è®­ç»ƒæˆåŠŸ: {success_count}/{total_count}")
            
            if test_results:
                print(f"  æµ‹è¯•å®Œæˆ: {len(test_results)} ä¸ªç®—æ³•")
            
            if gpu_id is not None:
                # æ˜¾ç¤ºæœ€ç»ˆGPUå†…å­˜ä½¿ç”¨
                memory_allocated = torch.cuda.memory_allocated(gpu_id) / 1024**3
                memory_cached = torch.cuda.memory_reserved(gpu_id) / 1024**3
                print(f"  GPU {gpu_id} æœ€ç»ˆå†…å­˜: {memory_allocated:.2f}GB / {memory_cached:.2f}GB")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­å®éªŒ")
        print(f"ğŸ“ å·²ç”Ÿæˆçš„ç»“æœä¿å­˜åœ¨: {path_manager.get_experiment_dir()}")
    except Exception as e:
        print(f"\nâŒ å®éªŒæ‰§è¡Œå¤±è´¥: {e}")
        if args.server_mode:
            import traceback
            traceback.print_exc()
        print(f"ğŸ“ éƒ¨åˆ†ç»“æœå¯èƒ½ä¿å­˜åœ¨: {path_manager.get_experiment_dir()}")


if __name__ == "__main__":
    main()