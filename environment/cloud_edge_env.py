# environment/cloud_edge_env.py
"""
äº‘è¾¹ç«¯ä¸‰å±‚æ¶æ„å¸è½½ç¯å¢ƒ - ç®€åŒ–ç‰ˆè®¾å¤‡æ¨¡å‹
- UE: CPUé¢‘ç‡ + ä»»åŠ¡è´Ÿè½½
- ES: CPUé¢‘ç‡ + ä»»åŠ¡è´Ÿè½½
- CS: CPUé¢‘ç‡ï¼ˆèµ„æºæ— é™ï¼‰
- è€ƒè™‘å·®å¼‚åŒ–é€šä¿¡å»¶è¿Ÿï¼šè¾¹ç¼˜é€šä¿¡å¿«ï¼Œäº‘ç«¯é€šä¿¡æ…¢
"""
import numpy as np
import gymnasium as gym
from gymnasium import spaces
from collections import defaultdict
from .device_models import UserEquipment, EdgeServer, CloudServer
from .task_generator import TaskGenerator, Task


class TaskExecution:
    """ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€è·Ÿè¸ª"""
    def __init__(self, task_id, device_id, task_workload, data_size, start_time, execution_time, node_type, node_id, original_task_deadline):
        self.task_id = task_id
        self.device_id = device_id  # å‘èµ·ä»»åŠ¡çš„è®¾å¤‡ID
        self.task_workload = task_workload    # CPUå‘¨æœŸæ•°
        self.data_size = data_size  # æ•°æ®å¤§å°
        self.start_time = start_time
        self.execution_time = execution_time
        self.remaining_time = execution_time
        self.node_type = node_type  # 'local', 'edge', 'cloud'
        self.node_id = node_id      # èŠ‚ç‚¹ID
        self.completed = False
        self.original_task_deadline = original_task_deadline  # åŸå§‹ä»»åŠ¡çš„æˆªæ­¢æ—¶é—´
        self.creation_step = 0  # ä»»åŠ¡åˆ›å»ºçš„step
        
    def is_deadline_violated(self, current_time):
        """æ£€æŸ¥æ˜¯å¦è¿åæˆªæ­¢æ—¶é—´"""
        expected_completion_time = self.start_time + self.execution_time
        return expected_completion_time > self.original_task_deadline
    
    def get_progress(self):
        """è·å–æ‰§è¡Œè¿›åº¦ (0-1)"""
        if self.execution_time == 0:
            return 1.0
        return max(0, (self.execution_time - self.remaining_time) / self.execution_time)


class CloudEdgeDeviceEnv(gym.Env):
    """äº‘è¾¹ç«¯ä¸‰å±‚æ¶æ„å¸è½½ç¯å¢ƒ - ç®€åŒ–è®¾å¤‡æ¨¡å‹ç‰ˆæœ¬"""
    
    def __init__(self, config):
        super(CloudEdgeDeviceEnv, self).__init__()

        self.config = config
        
        # åŸºç¡€é…ç½®
        self.num_devices = config.get('environment', {}).get('num_devices', 10)
        self.num_edges = config.get('environment', {}).get('num_edges', 5)
        self.num_clouds = config.get('environment', {}).get('num_clouds', 1)
        
        # ğŸš€ çœŸå®è¾¹ç¼˜ç¯å¢ƒä»»åŠ¡ç”Ÿæˆé…ç½®
        self.task_generation_config = {
            # åŸºç¡€æ³Šæ¾å‚æ•°
            'base_arrival_rate': 0.8,      # åŸºç¡€ä»»åŠ¡åˆ°è¾¾ç‡ï¼ˆæ¯è®¾å¤‡æ¯stepï¼‰
            'poisson_lambda': 1.2,         # æ³Šæ¾åˆ†å¸ƒå‚æ•°
            
            # æ—¶é—´æ¨¡å¼é…ç½®
            'time_pattern_enabled': True,   # å¯ç”¨æ—¶é—´æ¨¡å¼
            'peak_hours': [20, 40, 60, 80], # é«˜å³°æ—¶æ®µï¼ˆstepï¼‰
            'peak_multiplier': 2.5,         # é«˜å³°æœŸå€ç‡
            'low_multiplier': 0.4,          # ä½å³°æœŸå€ç‡
            'pattern_cycle': 20,            # æ¨¡å¼å‘¨æœŸï¼ˆstepï¼‰
            
            # çªå‘ä»»åŠ¡é…ç½®
            'burst_probability': 0.05,      # çªå‘æ¦‚ç‡ï¼ˆæ¯step 5%ï¼‰
            'burst_intensity': 3.0,         # çªå‘å¼ºåº¦å€ç‡
            'burst_duration': [2, 5],       # çªå‘æŒç»­æ—¶é—´èŒƒå›´
            
            # è´Ÿè½½æ§åˆ¶
            'max_concurrent_tasks': 200,    # å¢åŠ å¹¶å‘é™åˆ¶
            'device_load_threshold': 60.0,  # è®¾å¤‡è´Ÿè½½é˜ˆå€¼ï¼ˆç§’ï¼‰
            'system_load_threshold': 800.0, # ç³»ç»Ÿè´Ÿè½½é˜ˆå€¼ï¼ˆç§’ï¼‰
            'emergency_threshold': 1000.0,  # ç´§æ€¥é˜ˆå€¼
            
            # åº”ç”¨åœºæ™¯æ··åˆ
            'application_mix': {
                'iot_sensors': 0.4,         # IoTä¼ æ„Ÿå™¨æ•°æ®
                'mobile_apps': 0.3,         # ç§»åŠ¨åº”ç”¨
                'video_stream': 0.15,       # è§†é¢‘æµå¤„ç†
                'ai_inference': 0.1,        # AIæ¨ç†
                'emergency': 0.05           # ç´§æ€¥ä»»åŠ¡
            }
        }
        
        # ğŸš€ åŠ¨æ€æˆªæ­¢æ—¶é—´é…ç½®
        self.deadline_config = {
            'adaptive_deadline': True,
            'base_factors': {
                'iot_sensors': (2.0, 4.0),     # IoT: å®½æ¾æˆªæ­¢æ—¶é—´
                'mobile_apps': (1.5, 3.0),     # ç§»åŠ¨åº”ç”¨: ä¸­ç­‰æˆªæ­¢æ—¶é—´
                'video_stream': (1.2, 2.0),    # è§†é¢‘: ä¸¥æ ¼æˆªæ­¢æ—¶é—´
                'ai_inference': (1.8, 3.5),    # AI: ä¸­ç­‰åå®½æ¾
                'emergency': (1.1, 1.5)        # ç´§æ€¥: æä¸¥æ ¼æˆªæ­¢æ—¶é—´
            },
            'load_adjustment': True,
            'min_deadline': 2.0,
            'congestion_penalty': 1.5
        }

        # åˆ›å»ºè®¾å¤‡
        self._create_devices()

        # ä»»åŠ¡ç”Ÿæˆå™¨
        self.task_generator = TaskGenerator(config)
        
        # ğŸš€ çœŸå®åœºæ™¯ä»»åŠ¡ç±»å‹é‡æ–°å®šä¹‰
        self.task_generator.task_type_weights = {
            'small': 0.5,   # å°ä»»åŠ¡ï¼šIoTä¼ æ„Ÿå™¨ã€æ–‡æœ¬å¤„ç†
            'medium': 0.35, # ä¸­ä»»åŠ¡ï¼šå›¾åƒå¤„ç†ã€è½»åº¦AI
            'large': 0.15   # å¤§ä»»åŠ¡ï¼šè§†é¢‘åˆ†æã€å¤æ‚AI
        }
        
        # ğŸš€ åº”ç”¨åœºæ™¯ç‰¹å®šçš„ä»»åŠ¡å‚æ•°
        self.application_task_configs = {
            'iot_sensors': {
                'size_range': (0.1, 2.0),      # 0.1-2MB
                'compute_density': 0.05e9,      # ä½è®¡ç®—å¯†åº¦
                'priority': 'low'
            },
            'mobile_apps': {
                'size_range': (1.0, 20.0),     # 1-20MB
                'compute_density': 0.15e9,      # ä¸­è®¡ç®—å¯†åº¦
                'priority': 'medium'
            },
            'video_stream': {
                'size_range': (50.0, 150.0),   # 50-150MB
                'compute_density': 0.3e9,       # é«˜è®¡ç®—å¯†åº¦
                'priority': 'high'
            },
            'ai_inference': {
                'size_range': (10.0, 80.0),    # 10-80MB
                'compute_density': 0.25e9,      # é«˜è®¡ç®—å¯†åº¦
                'priority': 'medium'
            },
            'emergency': {
                'size_range': (0.5, 30.0),     # 0.5-30MB
                'compute_density': 0.1e9,       # å¯å˜è®¡ç®—å¯†åº¦
                'priority': 'critical'
            }
        }
        
        # ğŸš€ çœŸå®ç¯å¢ƒä»»åŠ¡ç”ŸæˆçŠ¶æ€
        self.task_generation_state = {
            'last_generation_step': -1,     # ä¸Šæ¬¡ç”Ÿæˆæ­¥æ•°
            'total_concurrent_tasks': 0,    # å½“å‰å¹¶å‘ä»»åŠ¡æ•°
            'burst_active': False,          # æ˜¯å¦åœ¨çªå‘æœŸ
            'burst_end_step': 0,           # çªå‘ç»“æŸæ­¥æ•°
            'current_pattern_phase': 'normal', # å½“å‰æ¨¡å¼ï¼šnormal/peak/low
            'generation_history': [],       # ç”Ÿæˆå†å²
            'daily_task_count': 0          # æ¯æ—¥ä»»åŠ¡è®¡æ•°
        }

        # çŠ¶æ€ç©ºé—´ç»´åº¦è®¡ç®—
        # UE: 3ä¸ªç‰¹å¾ Ã— num_devices
        # ES: 2ä¸ªç‰¹å¾ Ã— num_edges  
        # CS: 1ä¸ªç‰¹å¾ Ã— num_clouds
        # ä»»åŠ¡: 6ä¸ªç‰¹å¾ Ã— num_devices
        self.state_dim = (3 * self.num_devices + 
                         2 * self.num_edges + 
                         1 * self.num_clouds + 
                         6 * self.num_devices)

        # å®šä¹‰è§‚å¯Ÿå’ŒåŠ¨ä½œç©ºé—´
        self.observation_space = spaces.Box(
            low=0.0, high=1.0, shape=(self.state_dim,), dtype=np.float32
        )

        # åŠ¨ä½œç©ºé—´å®šä¹‰ï¼šæ¯ä¸ªè®¾å¤‡çš„ä¸‰å…ƒåˆ†å‰²å†³ç­– [Î±1, Î±2, Î±3, edge_id]
        self.action_space = spaces.Box(
            low=np.array([0.0, 0.0, 0.0, 0]),      # [Î±1, Î±2, Î±3, edge_id]
            high=np.array([1.0, 1.0, 1.0, self.num_edges - 1]),
            dtype=np.float32
        )

        # ä»»åŠ¡æ‰§è¡Œè·Ÿè¸ª
        self.current_tasks = None
        self.task_executions = defaultdict(list)  # æŒ‰èŠ‚ç‚¹åˆ†ç»„çš„æ‰§è¡Œé˜Ÿåˆ—
        self.completed_tasks_history = []  # å·²å®Œæˆä»»åŠ¡çš„å†å²è®°å½•
        self.global_time = 0.0  # å…¨å±€æ—¶é—´æ­¥
        self.time_step_duration = 1.0  # æ¯ä¸ªstepçš„æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        
        # Episodeæ§åˆ¶
        self.episode_step = 0
        
        # ä»é…ç½®ä¸­è¯»å–max_stepsï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç ä¸º100
        # ä¼˜å…ˆä»maddpgé…ç½®è¯»å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä»trainingé…ç½®è¯»å–ï¼Œå¦‚æœéƒ½ä¸å­˜åœ¨åˆ™é»˜è®¤ä¸º200
        self.max_steps = config.get('maddpg', {}).get('max_steps', 
                          config.get('training', {}).get('max_steps_per_episode', 200))
        print(f"ç¯å¢ƒåˆå§‹åŒ–: æœ€å¤§æ­¥æ•°è®¾ç½®ä¸º {self.max_steps}")
        
        # ğŸ†• ä»»åŠ¡ç”Ÿæˆæ§åˆ¶
        self.last_generation_step = 0  # ä¸Šæ¬¡ç”Ÿæˆä»»åŠ¡çš„æ­¥æ•°
        self.total_concurrent_tasks = 0  # å½“å‰å¹¶å‘ä»»åŠ¡æ•°
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.step_stats = {
            'tasks_completed': 0,
            'tasks_timeout': 0,
            'total_latency': 0.0,
            'total_energy': 0.0,
            'communication_latency': 0.0,
            'computation_latency': 0.0
        }
        
        # æ–°å¢ï¼šä»»åŠ¡å®Œæˆç‡ç»Ÿè®¡
        self.task_completion_stats = {
            'total_tasks_generated': 0,        # æ€»ç”Ÿæˆä»»åŠ¡æ•°
            'tasks_completed_on_time': 0,      # æŒ‰æ—¶å®Œæˆçš„ä»»åŠ¡æ•°
            'tasks_completed_late': 0,         # è¶…æ—¶å®Œæˆçš„ä»»åŠ¡æ•°
            'tasks_failed': 0,                 # å¤±è´¥ä»»åŠ¡æ•°
            'completion_times': [],            # ä»»åŠ¡å®Œæˆæ—¶é—´è®°å½•
            'deadline_violations': [],         # æˆªæ­¢æ—¶é—´è¿åè®°å½•
            'timeout_reasons': []              # è¶…æ—¶åŸå› è®°å½•
        }

    def _create_devices(self):
        """åˆ›å»ºäº‘è¾¹ç«¯ä¸‰å±‚è®¾å¤‡"""
        # åˆ›å»ºç«¯ä¾§è®¾å¤‡ï¼ˆå¼‚æ„CPUé¢‘ç‡ï¼š0.5-1.0 GHzï¼‰
        self.user_equipments = []
        for i in range(self.num_devices):
            ue = UserEquipment(i)
            self.user_equipments.append(ue)
            
        # åˆ›å»ºè¾¹ç¼˜æœåŠ¡å™¨ï¼ˆå¼‚æ„é…ç½®ï¼š{5, 6, 7, 8, 9} GHzï¼‰
        edge_frequencies = [5, 6, 7, 8, 9]
        self.edge_servers = []
        for i in range(self.num_edges):
            es = EdgeServer(i, edge_frequencies[i % len(edge_frequencies)])
            self.edge_servers.append(es)
            
        # åˆ›å»ºäº‘æœåŠ¡å™¨ï¼ˆ20 GHzï¼‰
        self.cloud_servers = []
        for i in range(self.num_clouds):
            cs = CloudServer(i)
            self.cloud_servers.append(cs)

    @property
    def devices(self):
        """è¿”å›æ‰€æœ‰ç”¨æˆ·è®¾å¤‡ï¼ˆç”¨äºLLMå’¨è¯¢ï¼‰"""
        return self.user_equipments

    @property 
    def edge_servers_list(self):
        """è¿”å›è¾¹ç¼˜æœåŠ¡å™¨åˆ—è¡¨"""
        return self.edge_servers
        
    @property
    def cloud_servers_list(self):
        """è¿”å›äº‘æœåŠ¡å™¨åˆ—è¡¨"""
        return self.cloud_servers

    def reset(self, seed=None, options=None):
        """é‡ç½®ç¯å¢ƒ"""
        if seed is not None:
            np.random.seed(seed)
            
        # é‡ç½®æ‰€æœ‰è®¾å¤‡çŠ¶æ€
        for ue in self.user_equipments:
            ue.reset()
        for es in self.edge_servers:
            es.reset()
        for cs in self.cloud_servers:
            cs.reset()

        # é‡ç½®ä»»åŠ¡æ‰§è¡Œè·Ÿè¸ª
        self.task_executions.clear()
        self.completed_tasks_history.clear()
        self.global_time = 0.0
        self.episode_step = 0
        
        # ğŸš€ é‡ç½®çœŸå®ç¯å¢ƒä»»åŠ¡ç”ŸæˆçŠ¶æ€
        self.task_generation_state = {
            'last_generation_step': -1,     # ä¸Šæ¬¡ç”Ÿæˆæ­¥æ•°
            'total_concurrent_tasks': 0,    # å½“å‰å¹¶å‘ä»»åŠ¡æ•°
            'burst_active': False,          # æ˜¯å¦åœ¨çªå‘æœŸ
            'burst_end_step': 0,           # çªå‘ç»“æŸæ­¥æ•°
            'current_pattern_phase': 'normal', # å½“å‰æ¨¡å¼ï¼šnormal/peak/low
            'generation_history': [],       # ç”Ÿæˆå†å²
            'daily_task_count': 0          # æ¯æ—¥ä»»åŠ¡è®¡æ•°
        }
        
        # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        self.step_stats = {
            'tasks_completed': 0,
            'tasks_timeout': 0,
            'total_latency': 0.0,
            'total_energy': 0.0,
            'communication_latency': 0.0,
            'computation_latency': 0.0
        }
        
        # æ–°å¢ï¼šä»»åŠ¡å®Œæˆç‡ç»Ÿè®¡
        self.task_completion_stats = {
            'total_tasks_generated': 0,        # æ€»ç”Ÿæˆä»»åŠ¡æ•°
            'tasks_completed_on_time': 0,      # æŒ‰æ—¶å®Œæˆçš„ä»»åŠ¡æ•°
            'tasks_completed_late': 0,         # è¶…æ—¶å®Œæˆçš„ä»»åŠ¡æ•°
            'tasks_failed': 0,                 # å¤±è´¥ä»»åŠ¡æ•°
            'completion_times': [],            # ä»»åŠ¡å®Œæˆæ—¶é—´è®°å½•
            'deadline_violations': [],         # æˆªæ­¢æ—¶é—´è¿åè®°å½•
            'timeout_reasons': []              # è¶…æ—¶åŸå› è®°å½•
        }
        
        # ç”Ÿæˆç¬¬ä¸€æ‰¹ä»»åŠ¡
        self._generate_new_tasks()

        return self._get_observation(), {}

    def _generate_new_tasks(self):
        """ğŸš€ ä½¿ç”¨åŸºç¡€ä»»åŠ¡ç”Ÿæˆå™¨ç”Ÿæˆä»»åŠ¡ - æ³Šæ¾åˆ†å¸ƒ + æ—¶é—´æ¨¡å¼"""
        print(f"\n[Step {self.episode_step}] ğŸŒŸ ç”Ÿæˆæ–°ä»»åŠ¡...")
        
        # ä½¿ç”¨åŸºç¡€ä»»åŠ¡ç”Ÿæˆå™¨çš„æ³Šæ¾ç”Ÿæˆé€»è¾‘
        if not hasattr(self, 'task_generator'):
            # åˆå§‹åŒ–ä»»åŠ¡ç”Ÿæˆå™¨
            from environment.task_generator import TaskGenerator
            
            # ä»é…ç½®ä¸­æå–ä»»åŠ¡ç”Ÿæˆå™¨ç›¸å…³é…ç½®
            task_config = {}
            if 'tasks' in self.config:
                task_config = self.config['tasks']
            
            # é…ç½®æ³Šæ¾å‚æ•°
            poisson_config = {
                'base_arrival_rate': self.task_generation_config.get('base_arrival_rate', 0.5),
                'time_pattern_enabled': self.task_generation_config.get('time_pattern_enabled', True),
                'pattern_cycle': self.task_generation_config.get('pattern_cycle', 20),
                'peak_hours': self.task_generation_config.get('peak_hours', [5, 15]),
                'peak_multiplier': self.task_generation_config.get('peak_multiplier', 2.0),
                'low_multiplier': self.task_generation_config.get('low_multiplier', 0.5),
            }
            
            task_config['poisson_config'] = poisson_config
            self.task_generator = TaskGenerator(task_config)
        
        # ä½¿ç”¨åŸºç¡€ä»»åŠ¡ç”Ÿæˆå™¨ç”Ÿæˆä»»åŠ¡
        device_tasks_dict = self.task_generator.generate_poisson_tasks(
            num_devices=self.num_devices,
            step=self.episode_step
        )
        
        # åˆ›å»ºä»»åŠ¡å¯¹è±¡
        self.current_tasks = []
        for device_id in range(self.num_devices):
            if device_id in device_tasks_dict and device_tasks_dict[device_id]:
                # å–è¯¥è®¾å¤‡çš„ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼ˆå¦‚æœæœ‰å¤šä¸ªï¼Œåªä¿ç•™ç¬¬ä¸€ä¸ªï¼‰
                task_data = device_tasks_dict[device_id][0]
                task = Task(task_data)
                task.creation_step = self.episode_step
                self.current_tasks.append(task)
                
                # æ›´æ–°ç»Ÿè®¡
                self.task_completion_stats['total_tasks_generated'] += 1
                self.task_generation_state['total_concurrent_tasks'] += 1
                self.task_generation_state['daily_task_count'] += 1
                
                # å¦‚æœè¯¥è®¾å¤‡æœ‰å¤šä¸ªä»»åŠ¡ï¼Œæ‰“å°æç¤ºï¼ˆä»…æµ‹è¯•ç”¨ï¼‰
                if len(device_tasks_dict[device_id]) > 1:
                    print(f"   è®¾å¤‡ {device_id} æœ‰ {len(device_tasks_dict[device_id])} ä¸ªä»»åŠ¡ï¼Œåªä¿ç•™ç¬¬ä¸€ä¸ª")
            else:
                self.current_tasks.append(None)
        
        # æ‰“å°ç”Ÿæˆç»“æœ
        valid_tasks = sum(1 for task in self.current_tasks if task is not None)
        print(f"   ğŸ“Š ç”Ÿæˆç»“æœ: {valid_tasks}/{self.num_devices}ä¸ªè®¾å¤‡æœ‰ä»»åŠ¡")
        print(f"   ğŸ’¼ å½“å‰å¹¶å‘ä»»åŠ¡: {self.task_generation_state['total_concurrent_tasks']}")
        print(f"   ğŸ“ˆ ç´¯è®¡ç”Ÿæˆä»»åŠ¡: {self.task_completion_stats['total_tasks_generated']}")
        
        # æ›´æ–°ç”Ÿæˆå†å²ï¼ˆä¿æŒä¸åŸä»£ç çš„å…¼å®¹æ€§ï¼‰
        self.task_generation_state['generation_history'].append({
            'step': self.episode_step,
            'total_generated': valid_tasks,
            'pattern_phase': self.task_generator.current_pattern_phase,
            'burst_active': self.task_generation_state.get('burst_active', False),
            'arrival_rate': self.task_generator.poisson_config['base_arrival_rate']
        })

    def _calculate_time_pattern_multiplier(self):
        """è®¡ç®—æ—¶é—´æ¨¡å¼å€ç‡"""
        if not self.task_generation_config['time_pattern_enabled']:
            return 1.0
            
        # è®¡ç®—åœ¨å‘¨æœŸä¸­çš„ä½ç½®
        cycle_position = self.episode_step % self.task_generation_config['pattern_cycle']
        
        # åˆ¤æ–­å½“å‰æ˜¯å¦åœ¨é«˜å³°æœŸ
        is_peak = any(abs(self.episode_step - peak) <= 2 for peak in self.task_generation_config['peak_hours'])
        
        if is_peak:
            self.task_generation_state['current_pattern_phase'] = 'peak'
            return self.task_generation_config['peak_multiplier']
        elif cycle_position < 5:  # å‘¨æœŸå‰25%ä¸ºä½å³°æœŸ
            self.task_generation_state['current_pattern_phase'] = 'low'
            return self.task_generation_config['low_multiplier']
        else:
            self.task_generation_state['current_pattern_phase'] = 'normal'
            return 1.0
    
    def _handle_burst_events(self):
        """å¤„ç†çªå‘äº‹ä»¶"""
        # æ£€æŸ¥å½“å‰çªå‘æ˜¯å¦ç»“æŸ
        if self.task_generation_state['burst_active']:
            if self.episode_step >= self.task_generation_state['burst_end_step']:
                self.task_generation_state['burst_active'] = False
                print(f"   ğŸ”¥ çªå‘äº‹ä»¶ç»“æŸ (step {self.episode_step})")
                return 1.0
            else:
                remaining = self.task_generation_state['burst_end_step'] - self.episode_step
                print(f"   ğŸ”¥ çªå‘äº‹ä»¶è¿›è¡Œä¸­ (å‰©ä½™{remaining}æ­¥)")
                return self.task_generation_config['burst_intensity']
        
        # æ£€æŸ¥æ˜¯å¦è§¦å‘æ–°çš„çªå‘äº‹ä»¶
        if np.random.random() < self.task_generation_config['burst_probability']:
            duration = np.random.randint(*self.task_generation_config['burst_duration'])
            self.task_generation_state['burst_active'] = True
            self.task_generation_state['burst_end_step'] = self.episode_step + duration
            
            print(f"   ğŸ”¥ æ–°çªå‘äº‹ä»¶è§¦å‘ï¼æŒç»­{duration}æ­¥")
            return self.task_generation_config['burst_intensity']
        
        return 1.0
    
    def _generate_poisson_tasks(self, device_id, arrival_rate):
        """ä¸ºå•ä¸ªè®¾å¤‡ä½¿ç”¨æ³Šæ¾åˆ†å¸ƒç”Ÿæˆä»»åŠ¡"""
        # ä½¿ç”¨æ³Šæ¾åˆ†å¸ƒç¡®å®šä»»åŠ¡æ•°é‡
        num_tasks = np.random.poisson(arrival_rate)
        
        # è€ƒè™‘è®¾å¤‡è´Ÿè½½é™åˆ¶
        device_load = self.user_equipments[device_id].calculate_task_load()
        if device_load > self.task_generation_config['device_load_threshold']:
            # è®¾å¤‡è¿‡è½½ï¼Œå‡å°‘ä»»åŠ¡ç”Ÿæˆ
            reduction_factor = min(device_load / self.task_generation_config['device_load_threshold'], 3.0)
            num_tasks = max(0, int(num_tasks / reduction_factor))
        
        # æ£€æŸ¥ç³»ç»Ÿæ€»è´Ÿè½½
        system_load = self._calculate_system_load()
        if system_load > self.task_generation_config['system_load_threshold']:
            num_tasks = 0  # ç³»ç»Ÿè¿‡è½½ï¼Œåœæ­¢ç”Ÿæˆ
        
        if num_tasks == 0:
            return []
        
        # ç”Ÿæˆå…·ä½“ä»»åŠ¡
        tasks = []
        for i in range(num_tasks):
            task_data = self._generate_realistic_task(device_id)
            tasks.append(task_data)
        
        return tasks
    
    def _generate_realistic_task(self, device_id):
        """ç”Ÿæˆç¬¦åˆçœŸå®åœºæ™¯çš„ä»»åŠ¡"""
        # 1. é€‰æ‹©åº”ç”¨ç±»å‹
        app_types = list(self.task_generation_config['application_mix'].keys())
        app_probs = list(self.task_generation_config['application_mix'].values())
        app_type = np.random.choice(app_types, p=app_probs)
        
        # 2. è·å–åº”ç”¨é…ç½®
        app_config = self.application_task_configs[app_type]
        
        # 3. ç”Ÿæˆä»»åŠ¡å¤§å°
        min_size, max_size = app_config['size_range']
        data_size = np.random.uniform(min_size, max_size)
        
        # 4. è®¡ç®—CPUå‘¨æœŸéœ€æ±‚
        cpu_cycles = data_size * app_config['compute_density']
        
        # 5. è®¾ç½®æˆªæ­¢æ—¶é—´
        deadline = self._calculate_realistic_deadline(app_type, data_size, cpu_cycles, device_id)
        
        # 6. ç”Ÿæˆå…¨å±€å”¯ä¸€ä»»åŠ¡ID
        task_id = f"{device_id}_{self.episode_step}_{self.task_completion_stats['total_tasks_generated']}"
        
        return {
            'task_id': task_id,
            'device_id': device_id,
            'type': app_type,
            'data_size': data_size,
            'cpu_cycles': cpu_cycles,
            'deadline': deadline,
            'priority': app_config['priority'],
            'arrival_time': self.global_time,
            'application_type': app_type
        }
    
    def _calculate_realistic_deadline(self, app_type, data_size, cpu_cycles, device_id):
        """è®¡ç®—ç¬¦åˆçœŸå®åœºæ™¯çš„æˆªæ­¢æ—¶é—´"""
        # 1. è·å–åŸºç¡€æˆªæ­¢æ—¶é—´å› å­
        base_factors = self.deadline_config['base_factors'][app_type]
        base_factor = np.random.uniform(*base_factors)
        
        # 2. è®¡ç®—æœ¬åœ°æ‰§è¡Œæ—¶é—´ï¼ˆä½¿ç”¨è¯¥è®¾å¤‡çš„CPUé¢‘ç‡ï¼‰
        device_cpu_freq = self.user_equipments[device_id].cpu_frequency * 1e9  # Hz
        local_execution_time = cpu_cycles / device_cpu_freq
        
        # 3. åŸºç¡€æˆªæ­¢æ—¶é—´
        base_deadline = local_execution_time * base_factor
        
        # 4. è´Ÿè½½è°ƒæ•´
        if self.deadline_config['load_adjustment']:
            system_load = self._calculate_system_load()
            if system_load > self.task_generation_config['system_load_threshold'] * 0.7:
                # ç³»ç»Ÿè´Ÿè½½è¾ƒé«˜ï¼Œé€‚å½“æ”¾å®½æˆªæ­¢æ—¶é—´
                congestion_factor = self.deadline_config['congestion_penalty']
                base_deadline *= congestion_factor
        
        # 5. ç¡®ä¿æœ€å°æˆªæ­¢æ—¶é—´
        final_deadline = max(base_deadline, self.deadline_config['min_deadline'])
        
        return final_deadline

    def _calculate_system_load(self):
        """è®¡ç®—ç³»ç»Ÿæ•´ä½“è´Ÿè½½"""
        total_load = 0.0
        
        # UEè´Ÿè½½
        for ue in self.user_equipments:
            total_load += ue.calculate_task_load()
            
        # ESè´Ÿè½½
        for es in self.edge_servers:
            total_load += es.calculate_task_load()
            
        return total_load

    def step(self, actions, llm_actions=None):
        """
        æ‰§è¡Œä¸€æ­¥åŠ¨ä½œ - è€ƒè™‘å·®å¼‚åŒ–é€šä¿¡å»¶è¿Ÿ
        
        Args:
            actions: Agentçš„åŠ¨ä½œ shape=(num_devices, 4) [Î±1, Î±2, Î±3, edge_id] æˆ– list
            llm_actions: LLMä¸“å®¶åŠ¨ä½œ shape=(num_devices, 4) æˆ– list
        
        Returns:
            observation, rewards, terminated, truncated, info
        """
        print(f"\n{'='*80}")
        print(f"å¼€å§‹æ‰§è¡Œ Step {self.episode_step + 1}")
        print(f"{'='*80}")
        
        self.episode_step += 1
        
        # 1. æ¨è¿›å…¨å±€æ—¶é—´ï¼Œæ›´æ–°æ‰€æœ‰è®¾å¤‡çš„ä»»åŠ¡çŠ¶æ€
        self.global_time += self.time_step_duration
        print(f"[Step {self.episode_step}] æ—¶é—´æ¨è¿›åˆ°: {self.global_time:.1f}s")
        
        # æ›´æ–°æ‰€æœ‰è®¾å¤‡çš„ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€
        self._update_all_devices(self.time_step_duration)
        
        # ğŸ”§ ç¡®ä¿actionsæ˜¯NumPyæ•°ç»„æ ¼å¼
        if not isinstance(actions, np.ndarray):
            actions = np.array(actions)
        
        # 2. æ˜¾ç¤ºMADDPGåŠ¨ä½œè§£æè¿‡ç¨‹
        print(f"\nğŸ”„ MADDPGåŠ¨ä½œç¯å¢ƒäº¤äº’è¿‡ç¨‹:")
        print(f"{'='*80}")
        print(f"æ¥æ”¶åˆ°çš„MADDPGåŠ¨ä½œç»´åº¦: {actions.shape}")
        print(f"åŠ¨ä½œå†…å®¹:")
        for i, action in enumerate(actions):
            alpha1, alpha2, alpha3, edge_id_raw = action
            edge_id = int(np.clip(edge_id_raw, 0, self.num_edges - 1))
            
            # å½’ä¸€åŒ–åˆ†å‰²æ¯”ä¾‹
            total = alpha1 + alpha2 + alpha3
            if total > 0:
                alpha1_norm, alpha2_norm, alpha3_norm = alpha1/total, alpha2/total, alpha3/total
            else:
                alpha1_norm, alpha2_norm, alpha3_norm = 1.0, 0.0, 0.0
            
            print(f"  Device{i}: åŸå§‹[{alpha1:.3f}, {alpha2:.3f}, {alpha3:.3f}, {edge_id_raw:.3f}]")
            print(f"           â†’ è§£æä¸º[æœ¬åœ°:{alpha1_norm:.3f}, è¾¹ç¼˜:{alpha2_norm:.3f}, äº‘ç«¯:{alpha3_norm:.3f}, Edge{edge_id}]")
        
        # 3. å¤„ç†æ–°ä»»åŠ¡çš„å¸è½½å†³ç­–
        print(f"\n[Step {self.episode_step}] ğŸš€ æ‰§è¡ŒMADDPGå¸è½½å†³ç­–...")
        rewards = np.zeros(self.num_devices)
        total_latencies = []
        total_energies = []
        communication_latencies = []
        computation_latencies = []
        has_task_list = []  # æ–°å¢ï¼šè®°å½•æ¯ä¸ªè®¾å¤‡æ˜¯å¦æœ‰ä»»åŠ¡

        for i in range(self.num_devices):
            # ğŸ”§ å®‰å…¨åœ°è·å–å•ä¸ªè®¾å¤‡çš„åŠ¨ä½œ
            if len(actions.shape) > 1:
                action = actions[i]
            else:
                action = actions
            
            reward, metrics = self._execute_offloading_decision(i, action)
            rewards[i] = reward
            
            # è®°å½•è¯¥è®¾å¤‡æ˜¯å¦æœ‰ä»»åŠ¡
            has_task = reward > 0.0  # å¦‚æœå¥–åŠ±ä¸º0ï¼Œè¯´æ˜æ²¡æœ‰ä»»åŠ¡
            has_task_list.append(has_task)
            
            total_latencies.append(metrics['total_latency'])  # æ€»æ—¶å»¶
            total_energies.append(metrics['total_energy'])  # æ€»èƒ½è€—
            communication_latencies.append(metrics['communication_latency'])  # é€šä¿¡æ—¶å»¶
            computation_latencies.append(metrics['computation_latency'])  # è®¡ç®—æ—¶å»¶
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.step_stats['total_latency'] += metrics['total_latency']
            self.step_stats['total_energy'] += metrics['total_energy']
            self.step_stats['communication_latency'] += metrics['communication_latency']
            self.step_stats['computation_latency'] += metrics['computation_latency']

        # æ˜¾ç¤ºå¥–åŠ±åé¦ˆ
        print(f"\nğŸ’° MADDPGåŠ¨ä½œå¥–åŠ±åé¦ˆ:")
        print(f"{'='*80}")
        for i, reward in enumerate(rewards):
            print(f"  Device{i}: å¥–åŠ±å€¼ = {reward:.3f}")
        
        # è®¡ç®—æœ‰ä»»åŠ¡è®¾å¤‡çš„å¹³å‡å¥–åŠ±
        valid_rewards = [r for r, has_task in zip(rewards, has_task_list) if has_task]
        if valid_rewards:
            avg_reward = np.mean(valid_rewards)
            min_reward = np.min(valid_rewards)
            max_reward = np.max(valid_rewards)
        else:
            avg_reward = 0.0
            min_reward = 0.0
            max_reward = 0.0
            
        print(f"  å¹³å‡å¥–åŠ±: {avg_reward:.3f} (ä»…è®¡ç®—æœ‰ä»»åŠ¡çš„è®¾å¤‡)")
        print(f"  å¥–åŠ±èŒƒå›´: [{min_reward:.3f}, {max_reward:.3f}]")

        # 4. æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        max_steps_reached = self.episode_step >= self.max_steps
        terminated = False
        truncated = max_steps_reached

        # 5. å¦‚æœè¿˜æ²¡ç»“æŸï¼Œä¸ºä¸‹ä¸€æ­¥ç”Ÿæˆæ–°ä»»åŠ¡
        if not (terminated or truncated):
            self._generate_new_tasks()

        # 6. æ‰“å°å½“å‰çŠ¶æ€æ€»ç»“
        self._print_step_summary()

        # æ„å»ºinfoå­—å…¸
        info = {
            'total_latencies': total_latencies,
            'total_energies': total_energies,
            'communication_latencies': communication_latencies,
            'computation_latencies': computation_latencies,
            'episode_step': self.episode_step,
            'global_time': self.global_time,
            'step_stats': self.step_stats.copy(),
            'llm_actions': llm_actions if llm_actions is not None else [],
            # æ–°å¢ï¼šä»»åŠ¡å®Œæˆç‡ç»Ÿè®¡
            'task_completion_stats': self.get_task_completion_rate(),
            'deadline_violations': self.task_completion_stats['deadline_violations'].copy(),
            'timeout_reasons': self.task_completion_stats['timeout_reasons'].copy(),
            # æ–°å¢ï¼šMADDPGåŠ¨ä½œä¿¡æ¯
            'maddpg_actions': actions.tolist(),
            'maddpg_rewards': rewards.tolist(),
            # æ–°å¢ï¼šæ¯ä¸ªè®¾å¤‡æ˜¯å¦æœ‰ä»»åŠ¡çš„æ ‡å¿—
            'has_task_list': has_task_list
        }

        return self._get_observation(), rewards, terminated, truncated, info

    def _update_all_devices(self, time_elapsed):
        """æ›´æ–°æ‰€æœ‰è®¾å¤‡çš„ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€"""
        # æ›´æ–°ç«¯ä¾§è®¾å¤‡
        for ue in self.user_equipments:
            ue.update_tasks(time_elapsed)
            
        # æ›´æ–°è¾¹ç¼˜æœåŠ¡å™¨
        for es in self.edge_servers:
            es.update_tasks(time_elapsed)
        
        # äº‘æœåŠ¡å™¨æ— éœ€æ›´æ–°ï¼ˆèµ„æºæ— é™ï¼Œä»»åŠ¡ç«‹å³æ‰§è¡Œï¼‰

    def _execute_offloading_decision(self, device_idx, action):
        """æ‰§è¡Œå•ä¸ªè®¾å¤‡çš„å¸è½½å†³ç­– - è€ƒè™‘å·®å¼‚åŒ–é€šä¿¡å»¶è¿Ÿ"""
        # ğŸ†• æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡éœ€è¦å¤„ç†
        if self.current_tasks is None or device_idx >= len(self.current_tasks):
            # æ²¡æœ‰ä»»åŠ¡ï¼Œè¿”å›é›¶å¥–åŠ±
            return 0.0, {
                'total_latency': 0.0,
                'total_energy': 0.0, 
                'communication_latency': 0.0,
                'computation_latency': 0.0,
                'local_baseline': (0.0, 0.0)
            }
        
        task = self.current_tasks[device_idx]
        if task is None:
            # è¯¥è®¾å¤‡æ²¡æœ‰ä»»åŠ¡ï¼Œè¿”å›é›¶å¥–åŠ±
            print(f"  Device{device_idx}: æ— ä»»åŠ¡åˆ†é…")
            return 0.0, {
                'total_latency': 0.0,
                'total_energy': 0.0,
                'communication_latency': 0.0, 
                'computation_latency': 0.0,
                'local_baseline': (0.0, 0.0)
            }
        
        # è§£æåŠ¨ä½œ
        alpha1, alpha2, alpha3, edge_id = action
        edge_id = int(np.clip(edge_id, 0, self.num_edges - 1))
        
        # å½’ä¸€åŒ–åˆ†å‰²æ¯”ä¾‹ï¼Œç¡®ä¿å’Œä¸º1
        total = alpha1 + alpha2 + alpha3
        if total > 0:
            alpha1, alpha2, alpha3 = alpha1/total, alpha2/total, alpha3/total
        else:
            alpha1, alpha2, alpha3 = 1.0, 0.0, 0.0  # é»˜è®¤å…¨æœ¬åœ°
            
        # è·å–è®¾å¤‡å’Œä»»åŠ¡
        ue = self.user_equipments[device_idx]
        task.set_split_ratios(alpha1, alpha2, alpha3)
        
        print(f"  Device{device_idx}: Task{task.task_id} åˆ†å‰²æ¯”ä¾‹ "
              f"[æœ¬åœ°:{alpha1:.2f}, è¾¹ç¼˜:{alpha2:.2f}, äº‘ç«¯:{alpha3:.2f}] â†’ Edge{edge_id}")
        
        # åˆ†å‰²ä»»åŠ¡å¹¶åˆ†é…åˆ°ä¸åŒèŠ‚ç‚¹
        total_latency, total_energy, comm_latency, comp_latency = self._schedule_task_execution_optimized(
            ue, task, edge_id, device_idx)
        
        # è®¡ç®—æœ¬åœ°åŸºå‡†
        baseline_latency, baseline_energy = self._calculate_local_baseline(ue, task)
        
        # è®¡ç®—å¥–åŠ±å‡½æ•°
        reward = self._calculate_reward(
            total_latency, total_energy, baseline_latency, baseline_energy, task.deadline, edge_id)
        
        metrics = {
            'total_latency': total_latency,
            'total_energy': total_energy,
            'communication_latency': comm_latency,
            'computation_latency': comp_latency,
            'local_baseline': (baseline_latency, baseline_energy)
        }
        
        return reward, metrics

    def _schedule_task_execution_optimized(self, ue, task, edge_id, device_idx):
        """
        ä¼˜åŒ–çš„ä»»åŠ¡è°ƒåº¦ - è€ƒè™‘å·®å¼‚åŒ–é€šä¿¡å»¶è¿Ÿå’Œä»»åŠ¡è´Ÿè½½
        
        è¿”å›: (æ€»å»¶è¿Ÿ, æ€»èƒ½è€—, é€šä¿¡å»¶è¿Ÿ, è®¡ç®—å»¶è¿Ÿ)
        """
        workloads = task.get_split_workloads()  # [æœ¬åœ°, è¾¹ç¼˜, äº‘ç«¯]å·¥ä½œè´Ÿè½½
        data_sizes = task.get_split_data_sizes()  # [æœ¬åœ°, è¾¹ç¼˜, äº‘ç«¯]æ•°æ®å¤§å°
        
        latencies = []
        energies = []
        comm_latencies = []
        comp_latencies = []
        
        # 1. æœ¬åœ°è®¡ç®—éƒ¨åˆ†
        if workloads[0] > 0:
            # è·å–å½“å‰ä»»åŠ¡è´Ÿè½½ï¼ˆç­‰å¾…æ—¶é—´ï¼‰
            current_load = ue.calculate_task_load()
            exec_time = ue.calculate_execution_time(workloads[0])
            energy = ue.calculate_energy_consumption(workloads[0])
            
            # æ·»åŠ ä»»åŠ¡åˆ°è®¾å¤‡é˜Ÿåˆ—
            ue.add_task(f"{task.task_id}_local", workloads[0], self.global_time)
            
            total_time = current_load + exec_time
            latencies.append(total_time)
            energies.append(energy)
            comm_latencies.append(0.0)  # æœ¬åœ°æ— é€šä¿¡å»¶è¿Ÿ
            comp_latencies.append(exec_time)
            

            
            print(f"    æœ¬åœ°æ‰§è¡Œ: {workloads[0]/1e9:.2f}Gcycles, "
                  f"ç­‰å¾…{current_load:.2f}s + è®¡ç®—{exec_time:.2f}s")
        else:
            latencies.append(0.0)
            energies.append(0.0)
            comm_latencies.append(0.0)
            comp_latencies.append(0.0)
            
        # 2. è¾¹ç¼˜è®¡ç®—éƒ¨åˆ†
        if workloads[1] > 0:
            es = self.edge_servers[edge_id]
            
            # é€šä¿¡å»¶è¿Ÿï¼ˆUEåˆ°è¾¹ç¼˜ï¼‰
            comm_time = ue.calculate_transmission_time_to_edge(data_sizes[1])
            comm_energy = ue.calculate_transmission_energy(comm_time)
            
            # è¾¹ç¼˜æœåŠ¡å™¨çš„ä»»åŠ¡è´Ÿè½½ï¼ˆç­‰å¾…æ—¶é—´ï¼‰
            edge_load = es.calculate_task_load()
            exec_time = es.calculate_execution_time(workloads[1])
            
            # æ·»åŠ ä»»åŠ¡åˆ°è¾¹ç¼˜é˜Ÿåˆ—
            es.add_task(f"{task.task_id}_edge", workloads[1], self.global_time + comm_time)
            
            total_time = comm_time + edge_load + exec_time
            latencies.append(total_time)
            energies.append(comm_energy)  # åªè®¡ç®—UEçš„ä¼ è¾“èƒ½è€—
            comm_latencies.append(comm_time)
            comp_latencies.append(exec_time)
            

            
            print(f"    è¾¹ç¼˜æ‰§è¡Œ: {workloads[1]/1e9:.2f}Gcycles â†’ ES{edge_id}, "
                  f"é€šä¿¡{comm_time:.2f}s + ç­‰å¾…{edge_load:.2f}s + è®¡ç®—{exec_time:.2f}s")
        else:
            latencies.append(0.0)
            energies.append(0.0)
            comm_latencies.append(0.0)
            comp_latencies.append(0.0)
            
        # 3. äº‘è®¡ç®—éƒ¨åˆ†ï¼ˆå·®å¼‚åŒ–é€šä¿¡å»¶è¿Ÿï¼‰
        if workloads[2] > 0:
            cs = self.cloud_servers[0]
            
            # é€šä¿¡å»¶è¿Ÿï¼ˆUEâ†’è¾¹ç¼˜â†’äº‘ï¼Œæ€»å»¶è¿Ÿæ›´é«˜ï¼‰
            comm_time = ue.calculate_transmission_time_to_cloud(data_sizes[2])
            comm_energy = ue.calculate_transmission_energy(comm_time * 0.6)  # éƒ¨åˆ†ä¼ è¾“æ—¶é—´çš„èƒ½è€—
            
            # äº‘è®¡ç®—æ—¶é—´ï¼ˆæ— ç­‰å¾…ï¼Œèµ„æºæ— é™ï¼‰
            exec_time = cs.calculate_execution_time(workloads[2])
            
            total_time = comm_time + exec_time
            latencies.append(total_time)
            energies.append(comm_energy)
            comm_latencies.append(comm_time)
            comp_latencies.append(exec_time)
            

            
            print(f"    äº‘ç«¯æ‰§è¡Œ: {workloads[2]/1e9:.2f}Gcycles â†’ Cloud, "
                  f"é€šä¿¡{comm_time:.2f}s + è®¡ç®—{exec_time:.2f}s")
        else:
            latencies.append(0.0)
            energies.append(0.0)
            comm_latencies.append(0.0)
            comp_latencies.append(0.0)
            
        # è®¡ç®—æ€»å»¶è¿Ÿï¼ˆå–æœ€å¤§å€¼ï¼Œå› ä¸ºå¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼‰å’Œæ€»èƒ½è€—ï¼ˆæ±‚å’Œï¼‰
        total_latency = max(latencies)
        total_energy = sum(energies)
        total_comm_latency = max(comm_latencies)
        total_comp_latency = max(comp_latencies)
        
        # æ£€æŸ¥ä»»åŠ¡å®ŒæˆçŠ¶æ€
        self._check_task_completion(task, total_latency)
        
        return total_latency, total_energy, total_comm_latency, total_comp_latency

    def _calculate_local_baseline(self, ue, task):
        """è®¡ç®—å…¨æœ¬åœ°æ‰§è¡Œçš„åŸºå‡†æ—¶å»¶å’Œèƒ½è€—"""
        current_load = ue.calculate_task_load()
        exec_time = ue.calculate_execution_time(task.task_workload)
        energy = ue.calculate_energy_consumption(task.task_workload)
        return current_load + exec_time, energy

    def _calculate_reward(self, offload_latency, offload_energy, 
                         baseline_latency, baseline_energy, deadline, edge_id=None):
        """
        è®¡ç®—å¥–åŠ±å‡½æ•°ï¼ŒåŒ…å«è´Ÿè½½å‡è¡¡å¥–åŠ±é¡¹
        
        Args:
            offload_latency: å¸è½½å»¶è¿Ÿ
            offload_energy: å¸è½½èƒ½è€—
            baseline_latency: åŸºå‡†å»¶è¿Ÿï¼ˆå…¨æœ¬åœ°æ‰§è¡Œï¼‰
            baseline_energy: åŸºå‡†èƒ½è€—ï¼ˆå…¨æœ¬åœ°æ‰§è¡Œï¼‰
            deadline: ä»»åŠ¡æˆªæ­¢æ—¶é—´
            edge_id: é€‰æ‹©çš„è¾¹ç¼˜æœåŠ¡å™¨IDï¼ˆå¦‚æœæœ‰ï¼‰
        
        Returns:
            float: å¥–åŠ±å€¼
        """
        # åŸºæœ¬å¥–åŠ±ï¼šå»¶è¿Ÿå’Œèƒ½è€—çš„å€’æ•°åŠ æƒ
        # é˜²æ­¢é™¤é›¶
        latency_term = 1.0 / offload_latency if offload_latency > 1e-8 else 0.0
        energy_term = 1.0 / offload_energy if offload_energy > 1e-8 else 0.0
        basic_reward = 0.5 * latency_term + 0.5 * energy_term
        
        # è´Ÿè½½å‡è¡¡å¥–åŠ±é¡¹
        load_balancing_reward = 0.0
        if edge_id is not None:
            # è®¡ç®—æ‰€æœ‰è¾¹ç¼˜æœåŠ¡å™¨çš„è´Ÿè½½å·®å¼‚
            loads = [es.calculate_task_load() for es in self.edge_servers]
            
            if sum(loads) > 0:  # ç¡®ä¿æœ‰è´Ÿè½½
                # è®¡ç®—è´Ÿè½½æ ‡å‡†å·®ï¼Œæ ‡å‡†å·®è¶Šå°è¡¨ç¤ºè¶Šå‡è¡¡
                mean_load = sum(loads) / len(loads)
                load_variance = sum((load - mean_load) ** 2 for load in loads) / len(loads)
                load_std = load_variance ** 0.5
                
                # è´Ÿè½½æ ‡å‡†å·®è¶Šå°ï¼Œå¥–åŠ±è¶Šå¤§
                # ä½¿ç”¨æŒ‡æ•°è¡°å‡å‡½æ•°ï¼Œå½“æ ‡å‡†å·®ä¸º0æ—¶å¥–åŠ±æœ€å¤§ä¸º0.2
                load_balancing_reward = 0.2 * np.exp(-2.0 * load_std)
                
                # é¢å¤–å¥–åŠ±ï¼šé€‰æ‹©è´Ÿè½½æœ€ä½çš„æœåŠ¡å™¨
                min_load_idx = np.argmin(loads)
                if edge_id == min_load_idx:
                    load_balancing_reward += 0.1
                    
                # è°ƒè¯•è¾“å‡º
                print(f"    è´Ÿè½½å‡è¡¡: å„æœåŠ¡å™¨è´Ÿè½½={[f'{load:.1f}' for load in loads]}, "
                      f"æ ‡å‡†å·®={load_std:.2f}, å¥–åŠ±={load_balancing_reward:.2f}")
        
        # æ€»å¥–åŠ± = åŸºæœ¬å¥–åŠ± + è´Ÿè½½å‡è¡¡å¥–åŠ±
        total_reward = basic_reward + load_balancing_reward
        
        return float(total_reward)

    def _print_step_summary(self):
        """æ‰“å°å½“å‰æ­¥éª¤çš„çŠ¶æ€æ€»ç»“"""
        print(f"\n[Step {self.episode_step}] çŠ¶æ€æ€»ç»“:")
        print(f"  å·²å®Œæˆä»»åŠ¡: {self.step_stats['tasks_completed']}")
        print(f"  è¶…æ—¶ä»»åŠ¡: {self.step_stats['tasks_timeout']}")
        
        # æ‰“å°è®¾å¤‡è´Ÿè½½çŠ¶æ€
        print("  ç«¯ä¾§è®¾å¤‡ä»»åŠ¡è´Ÿè½½:")
        for i in range(min(3, self.num_devices)):
            ue = self.user_equipments[i]
            load = ue.calculate_task_load()
            print(f"    UE{i}: ä»»åŠ¡è´Ÿè½½={load:.1f}s")
        
        print("  è¾¹ç¼˜æœåŠ¡å™¨è´Ÿè½½:")
        for i, es in enumerate(self.edge_servers):
            load = es.calculate_task_load()
            print(f"    ES{i}: CPU={es.cpu_frequency}GHz, è´Ÿè½½={load:.1f}s")

    def _get_observation(self):
        """
        è·å–ç¯å¢ƒè§‚å¯Ÿï¼ˆç®€åŒ–ç‰ˆï¼‰
        
        çŠ¶æ€ç»„æˆï¼š
        1. UEçŠ¶æ€ï¼šCPUé¢‘ç‡ã€ä»»åŠ¡è´Ÿè½½
        2. ESçŠ¶æ€ï¼šCPUé¢‘ç‡ã€ä»»åŠ¡è´Ÿè½½  
        3. CSçŠ¶æ€ï¼šCPUé¢‘ç‡
        4. ä»»åŠ¡çŠ¶æ€ï¼šç±»å‹ã€æ•°æ®å¤§å°ã€CPUå‘¨æœŸã€æˆªæ­¢æ—¶é—´ã€å‰©ä½™æ—¶é—´ã€ç´§æ€¥ç¨‹åº¦
        """
        observation = []
        
        # 1. UEçŠ¶æ€ (æ¯ä¸ªè®¾å¤‡2ä¸ªç‰¹å¾)
        for ue in self.user_equipments:
            ue_state = ue.get_state()  # [CPUé¢‘ç‡, ä»»åŠ¡è´Ÿè½½]
            observation.extend(ue_state)
            
        # 2. ESçŠ¶æ€ (æ¯ä¸ªæœåŠ¡å™¨2ä¸ªç‰¹å¾)
        for es in self.edge_servers:
            es_state = es.get_state()  # [CPUé¢‘ç‡, ä»»åŠ¡è´Ÿè½½]
            observation.extend(es_state)
            
        # 3. CSçŠ¶æ€ (æ¯ä¸ªæœåŠ¡å™¨1ä¸ªç‰¹å¾)
        for cs in self.cloud_servers:
            cs_state = cs.get_state()  # [CPUé¢‘ç‡]
            observation.extend(cs_state)
            
        # 4. ä»»åŠ¡çŠ¶æ€ (æ¯ä¸ªä»»åŠ¡6ä¸ªç‰¹å¾)
        if self.current_tasks:
            for i, task in enumerate(self.current_tasks):
                if task is not None:
                    # ä»»åŠ¡ç±»å‹å½’ä¸€åŒ–
                    if task.task_type == 'small':
                        task_type_norm = 0.0
                    elif task.task_type == 'medium':
                        task_type_norm = 0.5
                    else:
                        task_type_norm = 1.0
                        
                    # æ•°æ®å¤§å°å½’ä¸€åŒ– - ä¿®å¤å±æ€§åç§°
                    data_size_norm = min(task.task_data_size / 200.0, 1.0)
                    
                    # CPUå‘¨æœŸå½’ä¸€åŒ– - ä¿®å¤å±æ€§åç§°
                    workload_norm = min(task.task_workload / 1e10, 1.0)
                    
                    # æˆªæ­¢æ—¶é—´å½’ä¸€åŒ–
                    deadline_norm = min(task.deadline / 100.0, 1.0)
                    
                    # å‰©ä½™æ—¶é—´å½’ä¸€åŒ–
                    remaining_time = max(task.deadline - self.global_time, 0)
                    remaining_time_norm = min(remaining_time / 100.0, 1.0)
                    
                    # ç´§æ€¥ç¨‹åº¦
                    urgency = 1.0 - (remaining_time / task.deadline if task.deadline > 0 else 0)
                    
                    task_state = [
                        task_type_norm,
                        data_size_norm,
                        workload_norm,
                        deadline_norm,
                        remaining_time_norm,
                        urgency
                    ]
                else:
                    # æ²¡æœ‰ä»»åŠ¡ï¼Œå¡«å……é›¶
                    task_state = [0.0] * 6
                
                observation.extend(task_state)
        else:
            # å¦‚æœæ²¡æœ‰ä»»åŠ¡ï¼Œå¡«å……é›¶
            for _ in range(self.num_devices):
                observation.extend([0.0] * 6)
                
        return np.array(observation, dtype=np.float32)

    def extract_agent_state(self, global_state, agent_id):
        """
        æ­£ç¡®æå–å•ä¸ªAgentçš„è§‚å¯ŸçŠ¶æ€
        
        Args:
            global_state: å…¨å±€çŠ¶æ€å‘é‡ (101ç»´)
            agent_id: Agent ID (0åˆ°num_devices-1)
            
        Returns:
            agent_state: Agentçš„å±€éƒ¨çŠ¶æ€ (20ç»´)
            
        çŠ¶æ€ç»“æ„è¯´æ˜:
        - å…¨å±€çŠ¶æ€: [UEçŠ¶æ€(30ç»´) + ESçŠ¶æ€(10ç»´) + CSçŠ¶æ€(1ç»´) + ä»»åŠ¡çŠ¶æ€(60ç»´)] = 101ç»´
        - AgentçŠ¶æ€: [è‡ªå·±UEçŠ¶æ€(3ç»´) + æ‰€æœ‰ESçŠ¶æ€(10ç»´) + CSçŠ¶æ€(1ç»´) + è‡ªå·±ä»»åŠ¡çŠ¶æ€(6ç»´)] = 20ç»´
        """
        if agent_id < 0 or agent_id >= self.num_devices:
            raise ValueError(f"Agent ID {agent_id} è¶…å‡ºèŒƒå›´ [0, {self.num_devices-1}]")
        
        # çŠ¶æ€åˆ†å‰²ç‚¹è®¡ç®—
        ue_states_end = self.num_devices * 2
        es_states_end = ue_states_end + self.num_edges * 2
        cs_states_end = es_states_end + self.num_clouds * 1
        task_states_end = cs_states_end + self.num_devices * 6
        
        # 1. æå–å½“å‰Agentçš„UEçŠ¶æ€ (2ç»´)
        agent_ue_start = agent_id * 2
        agent_ue_state = global_state[agent_ue_start:agent_ue_start + 2]
        
        # 2. æå–æ‰€æœ‰è¾¹ç¼˜æœåŠ¡å™¨çŠ¶æ€ (10ç»´) - å…±äº«ä¿¡æ¯
        es_state = global_state[ue_states_end:es_states_end]
        
        # 3. æå–äº‘æœåŠ¡å™¨çŠ¶æ€ (1ç»´) - å…±äº«ä¿¡æ¯  
        cs_state = global_state[es_states_end:cs_states_end]
        
        # 4. æå–å½“å‰Agentçš„ä»»åŠ¡çŠ¶æ€ (6ç»´)
        agent_task_start = cs_states_end + agent_id * 6
        agent_task_state = global_state[agent_task_start:agent_task_start + 6]
        
        # ç»„åˆAgentçš„å®Œæ•´çŠ¶æ€
        agent_state = np.concatenate([
            agent_ue_state,    # 3ç»´ï¼šè‡ªå·±çš„è®¾å¤‡çŠ¶æ€
            es_state,          # 10ç»´ï¼šæ‰€æœ‰è¾¹ç¼˜æœåŠ¡å™¨çŠ¶æ€  
            cs_state,          # 1ç»´ï¼šäº‘æœåŠ¡å™¨çŠ¶æ€
            agent_task_state   # 6ç»´ï¼šè‡ªå·±çš„ä»»åŠ¡çŠ¶æ€
        ])
        
        return agent_state.astype(np.float32)

    def get_agent_state_dim(self):
        """è·å–å•ä¸ªAgentçš„çŠ¶æ€ç»´åº¦
        
        AgentçŠ¶æ€ç»“æ„ï¼š
        - è‡ªå·±UEçŠ¶æ€: 2ç»´ (CPUé¢‘ç‡, ä»»åŠ¡è´Ÿè½½)
        - æ‰€æœ‰ESçŠ¶æ€: 2Ã—5=10ç»´ (CPUé¢‘ç‡, ä»»åŠ¡è´Ÿè½½)
        - CSçŠ¶æ€: 1ç»´ (CPUé¢‘ç‡)
        - è‡ªå·±ä»»åŠ¡çŠ¶æ€: 6ç»´ (ä»»åŠ¡ç±»å‹, æ•°æ®å¤§å°, CPUå‘¨æœŸ, æˆªæ­¢æ—¶é—´, å‰©ä½™æ—¶é—´, ç´§æ€¥ç¨‹åº¦)
        
        æ€»è®¡: 2 + 10 + 1 + 6 = 19ç»´
        """
        return 2 + (self.num_edges * 2) + (self.num_clouds * 1) + 6

    def get_device_info(self):
        """è·å–è®¾å¤‡ä¿¡æ¯ï¼ˆç”¨äºLLMå’¨è¯¢ï¼‰"""
        device_info = []
        for i, ue in enumerate(self.user_equipments):
            info = {
                'device_id': i,
                'cpu_frequency': ue.cpu_frequency,
                'task_load': ue.calculate_task_load()
            }
            device_info.append(info)
        return device_info

    def get_edge_info(self):
        """è·å–è¾¹ç¼˜æœåŠ¡å™¨ä¿¡æ¯ï¼ˆç”¨äºLLMå’¨è¯¢ï¼‰"""
        edge_info = []
        for i, es in enumerate(self.edge_servers):
            info = {
                'server_id': i,
                'cpu_frequency': es.cpu_frequency,
                'task_load': es.calculate_task_load()
            }
            edge_info.append(info)
        return edge_info

    def get_cloud_info(self):
        """è·å–äº‘æœåŠ¡å™¨ä¿¡æ¯ï¼ˆç”¨äºLLMå’¨è¯¢ï¼‰"""
        cloud_info = []
        for i, cs in enumerate(self.cloud_servers):
            info = {
                'server_id': i,
                'cpu_frequency': cs.cpu_frequency,
                'is_available': True  # äº‘èµ„æºå§‹ç»ˆå¯ç”¨
            }
            cloud_info.append(info)
        return cloud_info

    def get_current_tasks_info(self):
        """è·å–å½“å‰ä»»åŠ¡ä¿¡æ¯ï¼ˆç”¨äºLLMå’¨è¯¢ï¼‰"""
        tasks_info = []
        if self.current_tasks:
            for i, task in enumerate(self.current_tasks):
                # ğŸ”§ ä¿®å¤ï¼šè¿‡æ»¤æ‰Noneä»»åŠ¡
                if task is not None:
                    info = {
                        'task_id': task.task_id,
                        'device_id': i,
                        'task_type': task.task_type,
                        'data_size': task.task_data_size,  # ä¿®å¤å±æ€§åç§°
                        'cpu_cycles': task.task_workload,     # ä¿®å¤å±æ€§åç§°
                        'deadline': task.deadline,
                        'remaining_time': max(task.deadline - self.global_time, 0)
                    }
                    tasks_info.append(info)
        return tasks_info

    def render(self, mode='human'):
        """æ¸²æŸ“ç¯å¢ƒçŠ¶æ€"""
        if mode == 'human':
            print("\n=== ç¯å¢ƒçŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆï¼‰===")
            print(f"Episode Step: {self.episode_step}")
            print(f"Global Time: {self.global_time:.1f}s")
            
            # æ˜¾ç¤ºè®¾å¤‡çŠ¶æ€
            print("\nè®¾å¤‡çŠ¶æ€:")
            for i in range(min(3, self.num_devices)):
                ue = self.user_equipments[i]
                load = ue.calculate_task_load()
                print(f"  UE{i}: CPU={ue.cpu_frequency:.1f}GHz, "
                      f"è´Ÿè½½={load:.1f}s")
            
            # æ˜¾ç¤ºè¾¹ç¼˜æœåŠ¡å™¨çŠ¶æ€
            print("\nè¾¹ç¼˜æœåŠ¡å™¨çŠ¶æ€:")
            for i, es in enumerate(self.edge_servers):
                load = es.calculate_task_load()
                print(f"  ES{i}: CPU={es.cpu_frequency}GHz, è´Ÿè½½={load:.1f}s")
            
            # æ˜¾ç¤ºäº‘æœåŠ¡å™¨çŠ¶æ€
            print("\näº‘æœåŠ¡å™¨çŠ¶æ€:")
            for i, cs in enumerate(self.cloud_servers):
                print(f"  CS{i}: CPU={cs.cpu_frequency}GHz (èµ„æºæ— é™)")

    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        pass

    def _check_task_completion(self, task, actual_latency):
        """
        æ£€æŸ¥å¹¶è®°å½•ä»»åŠ¡å®ŒæˆçŠ¶æ€
        
        Args:
            task: ä»»åŠ¡å¯¹è±¡
            actual_latency: å®é™…å®Œæˆå»¶è¿Ÿ
        """
        # ğŸ†• æ›´æ–°å¹¶å‘ä»»åŠ¡è®¡æ•°
        if self.task_generation_state['total_concurrent_tasks'] > 0:
            self.task_generation_state['total_concurrent_tasks'] -= 1
        
        # è®°å½•ä»»åŠ¡å®Œæˆæ—¶é—´
        completion_time = self.global_time + actual_latency
        self.task_completion_stats['completion_times'].append(completion_time)
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æˆªæ­¢æ—¶é—´
        if actual_latency <= task.deadline:
            # æŒ‰æ—¶å®Œæˆ
            self.task_completion_stats['tasks_completed_on_time'] += 1
            self.step_stats['tasks_completed'] += 1
            
            print(f"    âœ… ä»»åŠ¡{task.task_id}æŒ‰æ—¶å®Œæˆ: {actual_latency:.2f}s <= {task.deadline:.2f}s")
        else:
            # è¶…æ—¶å®Œæˆ
            overtime = actual_latency - task.deadline
            self.task_completion_stats['tasks_completed_late'] += 1
            self.task_completion_stats['deadline_violations'].append({
                'task_id': task.task_id,
                'task_type': task.task_type,
                'deadline': task.deadline,
                'actual_time': actual_latency,
                'overtime': overtime,
                'step': self.episode_step
            })
            self.step_stats['tasks_timeout'] += 1
            
            # è®°å½•è¶…æ—¶åŸå› 
            if overtime < 1.0:
                reason = "è½»å¾®è¶…æ—¶"
            elif overtime < 5.0:
                reason = "ä¸­åº¦è¶…æ—¶"
            else:
                reason = "ä¸¥é‡è¶…æ—¶"
            
            self.task_completion_stats['timeout_reasons'].append({
                'task_id': task.task_id,
                'reason': reason,
                'overtime': overtime
            })
            
            print(f"    âš ï¸ ä»»åŠ¡{task.task_id}è¶…æ—¶å®Œæˆ: {actual_latency:.2f}s > {task.deadline:.2f}s (è¶…æ—¶{overtime:.2f}s)")

    def get_task_completion_rate(self):
        """
        è®¡ç®—ä»»åŠ¡å®Œæˆç‡
        
        Returns:
            dict: åŒ…å«å„ç§å®Œæˆç‡æŒ‡æ ‡çš„å­—å…¸
        """
        stats = self.task_completion_stats
        total_attempted = stats['tasks_completed_on_time'] + stats['tasks_completed_late'] + stats['tasks_failed']
        
        if total_attempted == 0:
            return {
                'overall_completion_rate': 1.0,
                'on_time_completion_rate': 1.0,
                'timeout_rate': 0.0,
                'failure_rate': 0.0,
                'total_tasks': 0,
                'completed_on_time': 0,
                'completed_late': 0,
                'failed': 0
            }
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        overall_completion_rate = (stats['tasks_completed_on_time'] + stats['tasks_completed_late']) / total_attempted
        on_time_completion_rate = stats['tasks_completed_on_time'] / total_attempted
        timeout_rate = stats['tasks_completed_late'] / total_attempted
        failure_rate = stats['tasks_failed'] / total_attempted
        
        return {
            'overall_completion_rate': overall_completion_rate,        # æ€»å®Œæˆç‡ï¼ˆæŒ‰æ—¶+è¶…æ—¶ï¼‰
            'on_time_completion_rate': on_time_completion_rate,        # æŒ‰æ—¶å®Œæˆç‡
            'timeout_rate': timeout_rate,                              # è¶…æ—¶å®Œæˆç‡
            'failure_rate': failure_rate,                              # å¤±è´¥ç‡
            'total_tasks': total_attempted,                            # æ€»ä»»åŠ¡æ•°
            'completed_on_time': stats['tasks_completed_on_time'],     # æŒ‰æ—¶å®Œæˆæ•°
            'completed_late': stats['tasks_completed_late'],           # è¶…æ—¶å®Œæˆæ•°
            'failed': stats['tasks_failed'],                           # å¤±è´¥ä»»åŠ¡æ•°
            'avg_completion_time': np.mean(stats['completion_times']) if stats['completion_times'] else 0,
            'avg_overtime': np.mean([v['overtime'] for v in stats['deadline_violations']]) if stats['deadline_violations'] else 0
        }