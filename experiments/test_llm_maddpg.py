# experiments/test_llm_maddpg.py
import numpy as np
import torch
import random
import os
import gymnasium as gym
from environment.cloud_edge_env import CloudEdgeDeviceEnv
from algos.maddpg_agent import MADDPGAgent
from utils.config import load_config
from utils.path_manager import get_path_manager
from utils.csv_saver import save_test_results_csv


def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def test_llm_maddpg(model_path=None, config=None):
    """
    æµ‹è¯•ç»è¿‡LLM+MADDPGè®­ç»ƒçš„Agentåœ¨æ²¡æœ‰LLMæŒ‡å¯¼ä¸‹çš„è¡¨ç°
    è¿™ç›¸å½“äºæµ‹è¯•Agenté€šè¿‡çŸ¥è¯†è’¸é¦å­¦åˆ°çš„å†³ç­–èƒ½åŠ›
    """
    # åŠ è½½é…ç½®
    if config is None:
        config = load_config()
    set_seed(config.get('seed', 42))

    # ä½¿ç”¨è·¯å¾„ç®¡ç†å™¨
    path_manager = get_path_manager()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹è·¯å¾„ï¼Œè‡ªåŠ¨ä»è·¯å¾„ç®¡ç†å™¨è·å–
    if model_path is None:
        model_path = path_manager.get_model_path("llm_maddpg")

    print(f"ğŸ”§ [LLM+MADDPGæµ‹è¯•] é…ç½®ä¿¡æ¯:")
    print(f"  æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"  æµ‹è¯•ç»“æœä¿å­˜è·¯å¾„: {path_manager.get_test_results_path()}")
    print(f"  ğŸ§  æ³¨æ„: ä½¿ç”¨LLM+MADDPGè®­ç»ƒçš„æ¨¡å‹ï¼Œæµ‹è¯•æ—¶ä¸æä¾›LLMæŒ‡å¯¼")

    # åˆ›å»ºç¯å¢ƒï¼ˆä¸éœ€è¦LLMå®¢æˆ·ç«¯ï¼‰
    env = CloudEdgeDeviceEnv(config['environment'])

    # åˆ›å»ºMADDPGæ™ºèƒ½ä½“
    # ä½¿ç”¨æ­£ç¡®çš„å•ä¸ªAgentçŠ¶æ€ç»´åº¦  
    state_dim = env.get_agent_state_dim()  # 20ç»´ï¼š3(è‡ªå·±UE) + 10(æ‰€æœ‰ES) + 1(CS) + 6(è‡ªå·±ä»»åŠ¡)
    action_dim = env.action_space.shape[0]
    max_action = env.action_space.high[1] + 1  # ç›®æ ‡èŠ‚ç‚¹æ•°é‡
    num_agents = env.num_devices

    print(f"  å•ä¸ªAgentçŠ¶æ€ç»´åº¦: {state_dim}")
    print(f"  å…¨å±€çŠ¶æ€ç»´åº¦: {env.observation_space.shape[0]}")
    print(f"  åŠ¨ä½œç»´åº¦: {action_dim}")
    print(f"  è®¾å¤‡æ•°é‡: {num_agents}")

    agents = []
    model_loaded_count = 0
    for i in range(num_agents):
        agent = MADDPGAgent(
            state_dim=state_dim,
            action_dim=action_dim,
            max_action=max_action,
            num_agents=num_agents,
            agent_idx=i
        )

        # å°è¯•å¤šç§å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶æ ¼å¼
        possible_model_paths = [
            # LLM+MADDPGå®Œæ•´æ¨¡å‹æ ¼å¼ (æ¨è)
            f"{model_path}/agent_{i}_final.pth",
            f"{model_path}/agent_{i}.pth",
            os.path.join(model_path, f"agent_{i}_final.pth"),
            os.path.join(model_path, f"agent_{i}.pth"),
            # åˆ†ç¦»æ ¼å¼ (å¤‡ç”¨)
            f"{model_path}/actor_agent_{i}_final.pth",
            f"{model_path}/actor_agent_{i}.pth",
            os.path.join(model_path, f"actor_agent_{i}_final.pth"),
            os.path.join(model_path, f"actor_agent_{i}.pth")
        ]

        model_loaded = False
        
        # é¦–å…ˆå°è¯•åŠ è½½å®Œæ•´æ¨¡å‹æ ¼å¼
        for model_path_full in possible_model_paths[:4]:
            if os.path.exists(model_path_full):
                try:
                    if hasattr(agent, 'load_model'):
                        agent.load_model(model_path_full)
                        print(f"  âœ… åŠ è½½Agent {i} å®Œæ•´æ¨¡å‹: {model_path_full}")
                        model_loaded = True
                        break
                except Exception as e:
                    print(f"  âŒ åŠ è½½å®Œæ•´æ¨¡å‹å¤±è´¥ {model_path_full}: {e}")
        
        # å¦‚æœå®Œæ•´æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•åˆ†ç¦»æ ¼å¼
        if not model_loaded:
            actor_path = f"{model_path}/actor_agent_{i}_final.pth"
            critic_path = f"{model_path}/critic_agent_{i}_final.pth"
            
            if os.path.exists(actor_path):
                try:
                    agent.actor.load_state_dict(torch.load(actor_path))
                    agent.actor.eval()
                    print(f"  âœ… åŠ è½½Agent {i} Actor (åˆ†ç¦»æ ¼å¼): {actor_path}")
                    model_loaded = True
                except Exception as e:
                    print(f"  âŒ åŠ è½½Actorå¤±è´¥: {e}")

            if os.path.exists(critic_path):
                try:
                    agent.critic.load_state_dict(torch.load(critic_path))
                    agent.critic.eval()
                    print(f"  âœ… åŠ è½½Agent {i} Critic (åˆ†ç¦»æ ¼å¼): {critic_path}")
                except Exception as e:
                    print(f"  âŒ åŠ è½½Criticå¤±è´¥: {e}")

        if model_loaded:
            model_loaded_count += 1
        else:
            print(f"  âš ï¸  Agent {i} æ¨¡å‹åŠ è½½å¤±è´¥")

        agents.append(agent)

    if model_loaded_count == 0:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ¨¡å‹ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
        return [], [], []
    
    print(f"âœ… æˆåŠŸåŠ è½½ {model_loaded_count}/{num_agents} ä¸ªAgentçš„æ¨¡å‹")

    # æµ‹è¯•å‚æ•°
    num_episodes = config['testing']['num_episodes']
    max_steps = config['maddpg']['max_steps']

    # è®°å½•æ‰€æœ‰episodeçš„æŒ‡æ ‡
    all_episode_energy = []
    all_episode_delay = []
    all_episode_util = []

    print(f"\nğŸ§ª å¼€å§‹æµ‹è¯•ï¼Œå…±{num_episodes}è½®...")

    for episode in range(num_episodes):
        state, _ = env.reset()
        episode_reward = 0
        episode_energy = 0
        episode_delay = 0
        episode_util = 0
        step_count = 0

        if (episode + 1) % 20 == 0:
            print(f"\n[LLM+MADDPGçº¯Agentæ¨¡å¼] æµ‹è¯• Episode {episode + 1}/{num_episodes}")

        for step in range(max_steps):
            # é€‰æ‹©åŠ¨ä½œ - å…³é”®ä¿®æ”¹ï¼šä¸ä½¿ç”¨LLMæŒ‡å¯¼
            actions = []
            
            for i, agent in enumerate(agents):
                # ä½¿ç”¨æ­£ç¡®çš„AgentçŠ¶æ€æå–
                agent_state = env.extract_agent_state(state, i)
                
                # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šllm_advice=Noneï¼Œæµ‹è¯•Agentçš„çŸ¥è¯†è’¸é¦å­¦ä¹ æ•ˆæœ
                agent_action = agent.select_action(agent_state, add_noise=False, llm_advice=None)
                actions.append(agent_action)

            # æ‰§è¡ŒåŠ¨ä½œ
            next_state, rewards, terminated, truncated, info = env.step(actions)
            done = terminated or truncated

            # è¯¦ç»†ä¿¡æ¯è¾“å‡ºï¼ˆä»…éƒ¨åˆ†episodeï¼‰
            if (episode + 1) % 50 == 0 and step % 20 == 0:
                print(f"  æ­¥éª¤ {step} (çº¯Agentå†³ç­–):")
                for i, (action, reward) in enumerate(zip(actions, rewards)):
                    if len(action) >= 4:  # æ–°æ ¼å¼ [Î±1, Î±2, Î±3, edge_id]
                        alpha1, alpha2, alpha3, edge_id = action[:4]
                        print(f"    è®¾å¤‡ {i}: æœ¬åœ°={alpha1:.2f}, è¾¹ç¼˜={alpha2:.2f}, äº‘ç«¯={alpha3:.2f}, ç›®æ ‡è¾¹ç¼˜={int(edge_id)}, å¥–åŠ±={reward:.2f}")
                    else:  # æ—§æ ¼å¼ [offload_ratio, target_node]
                        offload_ratio = action[0]
                        target_node = int(action[1])
                        target_name = "æœ¬åœ°"
                        if target_node >= 1 and target_node <= env.num_edges:
                            target_name = f"è¾¹ç¼˜æœåŠ¡å™¨ {target_node - 1}"
                        elif target_node > env.num_edges:
                            target_name = "äº‘ç«¯"
                        print(f"    è®¾å¤‡ {i}: å¸è½½æ¯”ä¾‹={offload_ratio:.2f}, ç›®æ ‡={target_name}, å¥–åŠ±={reward:.2f}")

            # ç´¯åŠ èƒ½è€—ã€æ—¶å»¶ã€èµ„æºåˆ©ç”¨ç‡
            episode_energy += sum(info['energies'])
            episode_delay += sum(info['delays'])
            episode_util += sum(info['utilizations'])
            step_count += 1

            state = next_state
            episode_reward += sum(rewards)

            if done:
                if (episode + 1) % 20 == 0:
                    print(f"  Episode {episode + 1} å®Œæˆï¼Œæ€»å¥–åŠ±: {episode_reward:.2f}")
                break

        avg_energy = episode_energy / num_agents
        avg_delay = episode_delay / num_agents
        avg_util = episode_util / (num_agents * step_count) if step_count > 0 else 0
        all_episode_energy.append(avg_energy)
        all_episode_delay.append(avg_delay)
        all_episode_util.append(avg_util)
        
        if (episode + 1) % 10 == 0:
            print(f"[LLM+MADDPG] Episode {episode + 1}/{num_episodes} - "
                  f"èƒ½è€—: {avg_energy:.4f}, åˆ©ç”¨ç‡: {avg_util:.4f}, æ—¶å»¶: {avg_delay:.4f}")

    # è®¡ç®—æœ€ç»ˆç»Ÿè®¡ç»“æœ
    final_energy = np.mean(all_episode_energy)
    final_util = np.mean(all_episode_util)
    final_delay = np.mean(all_episode_delay)

    print(f"\nğŸ“Š [LLM+MADDPGçº¯Agentæ¨¡å¼] æµ‹è¯•å®Œæˆ!")
    print(f"  å¹³å‡èƒ½è€—: {final_energy:.4f}")
    print(f"  å¹³å‡èµ„æºåˆ©ç”¨ç‡: {final_util:.4f}")
    print(f"  å¹³å‡ä»»åŠ¡æ—¶å»¶: {final_delay:.4f}")
    print("ğŸ“‹ ç»“æœè¯´æ˜: æ­¤ç»“æœå±•ç¤ºäº†Agenté€šè¿‡çŸ¥è¯†è’¸é¦å­¦åˆ°çš„å†³ç­–èƒ½åŠ›")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    try:
        test_results = {
            'algorithm': 'LLM+MADDPG (Pure Agent)',
            'description': 'LLM+MADDPGè®­ç»ƒçš„Agentåœ¨æ— LLMæŒ‡å¯¼ä¸‹çš„æµ‹è¯•ç»“æœ',
            'num_episodes': num_episodes,
            'avg_energy': final_energy,
            'avg_utilization': final_util,
            'avg_delay': final_delay,
            'energy_std': np.std(all_episode_energy),
            'utilization_std': np.std(all_episode_util),
            'delay_std': np.std(all_episode_delay),
            'all_episode_energy': all_episode_energy,
            'all_episode_utilization': all_episode_util,
            'all_episode_delay': all_episode_delay
        }
        
        # ä¿å­˜åˆ°æµ‹è¯•ç»“æœç›®å½•
        import json
        result_file = path_manager.get_test_results_file_path("llm_maddpg_pure_agent_test_results.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(test_results, f, indent=2, ensure_ascii=False, default=str)
        print(f"  âœ… æµ‹è¯•ç»“æœä¿å­˜è‡³: {result_file}")
        
        # ä¿å­˜CSVæ ¼å¼çš„æµ‹è¯•ç»“æœ
        csv_file = save_test_results_csv(
            test_results=test_results,
            algorithm_name="LLM_MADDPG_Pure_Agent",
            save_dir=path_manager.get_test_results_path()
        )
        print(f"  âœ… CSVç»“æœä¿å­˜è‡³: {csv_file}")
        
    except Exception as e:
        print(f"  âŒ ä¿å­˜æµ‹è¯•ç»“æœå¤±è´¥: {e}")
        
    return all_episode_energy, all_episode_util, all_episode_delay

if __name__ == "__main__":
    test_llm_maddpg()