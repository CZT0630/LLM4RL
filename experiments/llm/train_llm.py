import numpy as np
import os
import random
import torch
import gymnasium as gym
from environment.cloud_edge_env import CloudEdgeDeviceEnv
from llm_assistant.llm_client import LLMClient
from llm_assistant.response_parser import ResponseParser
from utils.plotting import Plotter
from utils.metrics import MetricsTracker
from utils.config import load_config
from utils.path_manager import get_path_manager
from utils.csv_saver import save_training_metrics_csv

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def train_llm(config=None):
    # åŠ è½½é…ç½®
    if config is None:
        config = load_config()
    set_seed(config.get('seed', 42))

    # ğŸ†• ä½¿ç”¨è·¯å¾„ç®¡ç†å™¨
    path_manager = get_path_manager()
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    model_dir = path_manager.get_model_path("llm")
    data_dir = path_manager.get_data_path("csv")
    json_dir = path_manager.get_data_path("json")
    plot_dir = path_manager.get_plot_path()
    log_dir = path_manager.get_log_path()
    
    os.makedirs(model_dir, exist_ok=True)
    os.makedirs(data_dir, exist_ok=True)
    os.makedirs(json_dir, exist_ok=True)
    os.makedirs(plot_dir, exist_ok=True)
    os.makedirs(log_dir, exist_ok=True)

    # åˆ›å»ºç¯å¢ƒ
    env = CloudEdgeDeviceEnv(config)

    # åˆ›å»ºLLMå®¢æˆ·ç«¯
    llm_client = LLMClient(
        config=config,
        use_mock=config['llm'].get('use_mock_when_unavailable', True)
    )

    # è®­ç»ƒå‚æ•° - ä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„episodesï¼Œå¦åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
    max_episodes = config.get('training', {}).get('episodes', config['maddpg']['max_episodes'])
    max_steps = config['maddpg']['max_steps']
    num_agents = env.num_devices

    plotter = Plotter(plot_dir)
    metrics_tracker = MetricsTracker()
    all_actions = []
    episode_completion_rates = []  # æ–°å¢ï¼šè®°å½•æ¯ä¸ªepisodeçš„ä»»åŠ¡å®Œæˆç‡

    print(f"ğŸ”§ [LLM] è®­ç»ƒé…ç½®:")
    print(f"  è®­ç»ƒè½®æ•°: {max_episodes}")
    print(f"  æ¯è½®æœ€å¤§æ­¥æ•°: {max_steps}")
    print(f"  è®¾å¤‡æ•°é‡: {num_agents}")
    print(f"  ç»“æœä¿å­˜è·¯å¾„: {path_manager.get_experiment_dir()}")

    for episode in range(max_episodes):
        state, _ = env.reset()
        episode_reward = 0
        episode_latencies = []  # ğŸ†• æ”¶é›†æ¯æ­¥çš„å»¶è¿Ÿ
        episode_energies = []   # ğŸ†• æ”¶é›†æ¯æ­¥çš„èƒ½è€—
        step_means = []  # æ–°å¢ï¼šæ”¶é›†æ¯ä¸ªstepæ‰€æœ‰æ™ºèƒ½ä½“rewardçš„å‡å€¼
        
        for step in range(max_steps):
            # è·å–LLMç­–ç•¥å¹¶æ‰§è¡Œ
            device_info = [{
                "device_id": d.device_id,
                "cpu_frequency": d.cpu_frequency,
                "battery_percentage": d.get_battery_percentage(),
                "task_load": d.calculate_task_load()
            } for d in env.devices]
            edge_info = [{
                "server_id": e.server_id if hasattr(e, 'server_id') else i,
                "cpu_frequency": e.cpu_frequency,
                "task_load": e.calculate_task_load() if hasattr(e, 'calculate_task_load') else 0.0
            } for i, e in enumerate(env.edge_servers_list)]
            cloud_info = [{
                "server_id": c.server_id if hasattr(c, 'server_id') else i,
                "cpu_frequency": c.cpu_frequency
            } for i, c in enumerate(env.cloud_servers_list)]
            
            # è·å–æ ¼å¼1çš„LLMç­–ç•¥
            llm_strategies = llm_client.get_unload_strategy(state, device_info, edge_info, cloud_info)
            
            # è§£æLLMå“åº”ï¼ˆæ ¼å¼1ï¼‰
            parsed_strategies = ResponseParser.parse_unload_strategy(
                llm_strategies,
                env.num_devices,
                env.num_edges,
                env.num_clouds
            )
            
            # å°†æ ¼å¼1ç­–ç•¥è½¬æ¢ä¸ºç¯å¢ƒå¯æ¥å—çš„åŠ¨ä½œæ ¼å¼ [Î±1, Î±2, Î±3, edge_id]
            action_list = []
            for device_idx in range(env.num_devices):
                device_strategy = next(
                    (s for s in parsed_strategies if s["device_id"] == device_idx), 
                    {
                        "device_id": device_idx,
                        "local_ratio": 1.0,
                        "edge_ratio": 0.0,
                        "cloud_ratio": 0.0,
                        "target_edge": 0
                    }
                )
                
                # è½¬æ¢ä¸ºç¯å¢ƒåŠ¨ä½œæ ¼å¼
                action = [
                    device_strategy["local_ratio"],   # Î±1: æœ¬åœ°æ‰§è¡Œæ¯”ä¾‹
                    device_strategy["edge_ratio"],    # Î±2: è¾¹ç¼˜æ‰§è¡Œæ¯”ä¾‹  
                    device_strategy["cloud_ratio"],   # Î±3: äº‘ç«¯æ‰§è¡Œæ¯”ä¾‹
                    device_strategy["target_edge"]    # edge_id: ç›®æ ‡è¾¹ç¼˜æœåŠ¡å™¨
                ]
                action_list.append(action)
                
            actions = np.array(action_list)
            all_actions.append(actions)
            
            # æ‰§è¡ŒåŠ¨ä½œ
            next_state, rewards, terminated, truncated, info = env.step(actions)
            done = terminated or truncated
            state = next_state
            
            # è®°å½•æœ¬stepæ‰€æœ‰æ™ºèƒ½ä½“rewardçš„å‡å€¼ï¼ˆåªè€ƒè™‘æœ‰ä»»åŠ¡çš„è®¾å¤‡ï¼‰
            if info and 'has_task_list' in info:
                valid_rewards = [r for r, has_task in zip(rewards, info['has_task_list']) if has_task]
                if valid_rewards:
                    step_means.append(np.mean(valid_rewards))
            else:
                # å¦‚æœæ²¡æœ‰has_task_listï¼Œåˆ™è¿‡æ»¤æ‰0å¥–åŠ±ï¼ˆå‡è®¾0å¥–åŠ±è¡¨ç¤ºæ— ä»»åŠ¡ï¼‰
                valid_rewards = [r for r in rewards if r > 0]
                if valid_rewards:
                    step_means.append(np.mean(valid_rewards))
                else:
                    step_means.append(np.mean(rewards))  # å¦‚æœæ‰€æœ‰å¥–åŠ±éƒ½ä¸º0ï¼Œåˆ™ä½¿ç”¨å…¨éƒ¨å‡å€¼
            
            # ğŸ†• ä»infoä¸­æå–å»¶è¿Ÿå’Œèƒ½è€—ï¼Œè¿‡æ»¤é›¶å€¼
            if info:
                step_latencies = info.get('total_latencies', [])
                step_energies = info.get('total_energies', [])
                has_task_list = info.get('has_task_list', [True] * len(step_latencies))  # é»˜è®¤æ‰€æœ‰è®¾å¤‡éƒ½æœ‰ä»»åŠ¡
                
                # åªä¿ç•™æœ‰ä»»åŠ¡çš„è®¾å¤‡çš„å»¶è¿Ÿå’Œèƒ½è€—æ•°æ®
                valid_latencies = [lat for lat, has_task in zip(step_latencies, has_task_list) if has_task and lat > 0]
                valid_energies = [eng for eng, has_task in zip(step_energies, has_task_list) if has_task and eng > 0]
                
                if valid_latencies:
                    episode_latencies.extend(valid_latencies)
                if valid_energies:
                    episode_energies.extend(valid_energies)
            
            if done:
                break
        
        # ç»Ÿä¸€episode rewardè®¡ç®—æ–¹å¼
        episode_reward = np.mean(step_means) if step_means else 0.0
        
        # Episode ç»“æŸï¼Œç»Ÿè®¡æŒ‡æ ‡
        # ä½¿ç”¨å®é™…ä»»åŠ¡å®Œæˆç‡è€Œä¸æ˜¯å›ºå®šå€¼
        completion_stats = env.get_task_completion_rate()
        episode_completion_rate = completion_stats.get('on_time_completion_rate', 0.0)
        
        # è®°å½•æœ¬è½®çš„ä»»åŠ¡å®Œæˆç‡
        episode_completion_rates.append(episode_completion_rate)
        
        # è®¡ç®—å¹³å‡å»¶è¿Ÿå’Œèƒ½è€—
        avg_latency = np.mean(episode_latencies) if episode_latencies else 0.0
        avg_energy = np.mean(episode_energies) if episode_energies else 0.0
        
        # ğŸ†• æ­£ç¡®ä¼ å…¥å»¶è¿Ÿå’Œèƒ½è€—æŒ‡æ ‡
        metrics_tracker.add_episode(episode_reward, avg_latency, avg_energy, True)
        
        if (episode + 1) % 10 == 0:
            avg_metrics = metrics_tracker.get_average_metrics(last_n=10)
            print(f"[LLM] Episode {episode + 1}/{max_episodes}")
            print(f"  å¹³å‡å¥–åŠ±: {avg_metrics['avg_reward']:.2f}")
            print(f"  å¹³å‡å»¶è¿Ÿ: {avg_metrics['avg_delay']:.2f}s")
            print(f"  å¹³å‡èƒ½è€—: {avg_metrics['avg_energy']:.2f}J")
            
        if (episode + 1) % 100 == 0:
            plotter.plot_rewards(metrics_tracker.episode_rewards)
            if all_actions:
                # ç»˜åˆ¶åŠ¨ä½œåˆ†å¸ƒï¼ˆ4ç»´åŠ¨ä½œï¼‰
                plotter.plot_action_distribution(np.array(all_actions).reshape(-1, 4))
                
    plotter.plot_rewards(metrics_tracker.episode_rewards)
    if all_actions:
        plotter.plot_action_distribution(np.array(all_actions).reshape(-1, 4))
        
    # ğŸ†• ä¿å­˜æ ¸å¿ƒæŒ‡æ ‡åˆ°CSVè¡¨æ ¼ - ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
    print("ä¿å­˜è®­ç»ƒæŒ‡æ ‡åˆ°CSVè¡¨æ ¼...")
    try:
        csv_filepath = save_training_metrics_csv(
            episode_rewards=metrics_tracker.episode_rewards,
            episode_latencies=metrics_tracker.episode_delays,
            episode_energies=metrics_tracker.episode_energy,
            episode_completion_rates=episode_completion_rates,  # ä½¿ç”¨åŠ¨æ€è®°å½•çš„å®Œæˆç‡åˆ—è¡¨
            algorithm_name="Pure_LLM",
            save_dir=data_dir  # ğŸ†• ä½¿ç”¨è·¯å¾„ç®¡ç†å™¨çš„ç›®å½•
        )
        print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜: {csv_filepath}")
    except Exception as e:
        print(f"âŒ ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
        
    print("[LLM] è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {path_manager.get_experiment_dir()}")
    
    # è¿”å›å®Œæ•´ç»“æœ
    return {
        'episode_rewards': metrics_tracker.episode_rewards,
        'episode_latencies': metrics_tracker.episode_delays,
        'episode_energies': metrics_tracker.episode_energy,
        'episode_completion_rates': episode_completion_rates,  # ä½¿ç”¨åŠ¨æ€è®°å½•çš„å®Œæˆç‡åˆ—è¡¨
        'training_losses': [],  # LLMæ²¡æœ‰è®­ç»ƒæŸå¤±
        'global_step_count': max_episodes * max_steps
    }

if __name__ == "__main__":
    train_llm() 